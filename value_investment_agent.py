#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»·å€¼æŠ•èµ„Agent - èåˆå·´è²ç‰¹ã€æŸ¥ç†èŠ’æ ¼ã€æ ¼é›·å„å§†çš„æŠ•èµ„æ™ºæ…§
æ”¯æŒå®æ—¶PEè·å–ï¼Œå‡å°‘APIè°ƒç”¨çš„æ™ºèƒ½ç­›é€‰ï¼Œå¹¶é›†æˆDeepSeek AIåˆ†æ
"""

import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from loguru import logger
import argparse
import json
import time
import random
import requests

# Tushare APIç›¸å…³å¯¼å…¥
try:
    import tushare as ts
    TUSHARE_AVAILABLE = True
except ImportError:
    TUSHARE_AVAILABLE = False
    logger.warning("Tushareæœªå®‰è£…ï¼Œå°†æ— æ³•è·å–å®æ—¶PEæ•°æ®")

class DeepSeekAnalyzer:
    """DeepSeek AIåˆ†æå™¨"""
    
    def __init__(self, api_key: str = None, base_url: str = "https://api.deepseek.com", model: str = "deepseek-chat"):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        } if api_key else None
        
        # åŠ è½½ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self.load_system_prompt()
    
    def load_system_prompt(self) -> str:
        """åŠ è½½ç³»ç»Ÿæç¤ºè¯"""
        try:
            with open('system_prompt.md', 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning("æœªæ‰¾åˆ°system_prompt.mdæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            return "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä»·å€¼æŠ•èµ„åˆ†æå¸ˆï¼Œè¯·å¯¹æä¾›çš„è‚¡ç¥¨æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æã€‚"
    
    def analyze_stock(self, stock_code: str, stock_data: Dict, score_details: Dict) -> Optional[str]:
        """ä½¿ç”¨DeepSeekåˆ†æå•ä¸ªè‚¡ç¥¨"""
        if not self.api_key or not self.headers:
            logger.warning("DeepSeek API Keyæœªé…ç½®ï¼Œè·³è¿‡AIåˆ†æ")
            return None
        
        try:
            # æ„å»ºåˆ†æç”¨çš„æ•°æ®æ‘˜è¦
            data_summary = self.format_stock_data(stock_code, stock_data, score_details)
            
            # æ„å»ºè¯·æ±‚
            payload = {
                "model": self.model,
                "messages": [
                    {
                        "role": "system",
                        "content": self.system_prompt
                    },
                    {
                        "role": "user",
                        "content": f"è¯·å¯¹ä»¥ä¸‹Aè‚¡ä¸Šå¸‚å…¬å¸è¿›è¡Œæ·±åº¦ä»·å€¼æŠ•èµ„åˆ†æï¼š\n\n{data_summary}"
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 3000
            }
            
            # å‘é€è¯·æ±‚
            api_url = self.base_url
            if not api_url.endswith('/chat/completions'):
                api_url = api_url.rstrip('/') + '/chat/completions'
            
            response = requests.post(
                api_url,
                headers=self.headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis = result['choices'][0]['message']['content']
                logger.info(f"å®Œæˆ{stock_code}çš„DeepSeek AIåˆ†æ")
                return analysis
            else:
                logger.error(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"DeepSeekåˆ†æ{stock_code}æ—¶å‡ºé”™: {e}")
            return None
    
    def format_stock_data(self, stock_code: str, stock_data: Dict, score_details: Dict) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨æ•°æ®ä¸ºåˆ†æç”¨çš„æ–‡æœ¬"""
        basic_info = stock_data.get('basic_info', {})
        metrics = stock_data.get('metrics', {})
        
        # åŸºæœ¬ä¿¡æ¯
        company_name = basic_info.get('stock_name', 'æœªçŸ¥')
        industry = basic_info.get('industry', 'æœªçŸ¥')
        
        # è¯„åˆ†ä¿¡æ¯
        total_score = score_details.get('total_score', 0)
        buffett_score = score_details.get('buffett', {}).get('score', 0)
        munger_score = score_details.get('munger', {}).get('score', 0)
        graham_score = score_details.get('graham', {}).get('score', 0)
        
        # å…³é”®è´¢åŠ¡æŒ‡æ ‡
        data_text = f"""
è‚¡ç¥¨ä»£ç ï¼š{stock_code}
å…¬å¸åç§°ï¼š{company_name}
æ‰€å±è¡Œä¸šï¼š{industry}

ã€ä»·å€¼æŠ•èµ„è¯„åˆ†ã€‘
æ€»åˆ†ï¼š{total_score:.1f}/100
- å·´è²ç‰¹ç­–ç•¥å¾—åˆ†ï¼š{buffett_score:.1f}/100
- èŠ’æ ¼ç­–ç•¥å¾—åˆ†ï¼š{munger_score:.1f}/100  
- æ ¼é›·å„å§†ç­–ç•¥å¾—åˆ†ï¼š{graham_score:.1f}/100

ã€å…³é”®è´¢åŠ¡æŒ‡æ ‡ã€‘ï¼ˆè¿‘5å¹´æ•°æ®ï¼‰
"""
        
        # æ·»åŠ é‡è¦çš„è´¢åŠ¡æŒ‡æ ‡
        key_metrics = [
            ('å‡€èµ„äº§æ”¶ç›Šç‡(%)', 'roe'),
            ('å¸‚ç›ˆç‡', 'pe_ratio'),
            ('å¸‚å‡€ç‡', 'pb_ratio'),
            ('å‡€åˆ©æ¶¦(ä¸‡å…ƒ)', 'net_profit'),
            ('è¥ä¸šæ”¶å…¥(ä¸‡å…ƒ)', 'operating_income'),
            ('èµ„äº§è´Ÿå€ºç‡(%)', 'debt_to_asset_ratio'),
            ('æµåŠ¨æ¯”ç‡', 'current_ratio'),
            ('é€ŸåŠ¨æ¯”ç‡', 'quick_ratio'),
            ('æ¯è‚¡æ”¶ç›Š(å…ƒ)', 'eps'),
            ('æ¯è‚¡å‡€èµ„äº§(å…ƒ)', 'book_value_per_share'),
            ('æ¯›åˆ©ç‡(%)', 'gross_profit_margin'),
            ('å‡€åˆ©ç‡(%)', 'net_profit_margin')
        ]
        
        for metric_name, metric_key in key_metrics:
            if metric_key in metrics:
                metric_data = metrics[metric_key]
                values = []
                for year in sorted(metric_data.keys(), reverse=True)[:5]:  # æœ€è¿‘5å¹´
                    value = metric_data[year]
                    if pd.notna(value):
                        values.append(f"{year}å¹´: {value}")
                
                if values:
                    data_text += f"\n{metric_name}ï¼š{' | '.join(values)}"
        
        # æ·»åŠ è¯„åˆ†è¯¦æƒ…
        data_text += f"\n\nã€è¯¦ç»†è¯„åˆ†åˆ†æã€‘"
        
        for strategy, details in score_details.items():
            if strategy in ['buffett', 'munger', 'graham'] and isinstance(details, dict):
                data_text += f"\n\n{strategy.title()}ç­–ç•¥è¯„åˆ†è¯¦æƒ…ï¼š"
                for criterion, score in details.get('scores', {}).items():
                    data_text += f"\n- {criterion}: {score}åˆ†"
        
        return data_text

class TushareManager:
    """Tushare APIç®¡ç†å™¨ - æ”¯æŒå¤štokenå’Œæ™ºèƒ½é‡è¯•"""
    
    def __init__(self, tokens: List[str]):
        if not TUSHARE_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…tushare: pip install tushare")
        
        self.tokens = tokens
        self.current_token_index = 0
        self.pro = None
        self.init_api()
        
    def init_api(self):
        """åˆå§‹åŒ–APIè¿æ¥"""
        if self.tokens:
            current_token = self.tokens[self.current_token_index]
            self.pro = ts.pro_api(current_token)
            logger.info(f"ä½¿ç”¨Tushare Token {self.current_token_index + 1}/{len(self.tokens)}")
    
    def switch_token(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªtoken"""
        if len(self.tokens) > 1:
            self.current_token_index = (self.current_token_index + 1) % len(self.tokens)
            self.init_api()
            logger.info(f"åˆ‡æ¢åˆ°Token {self.current_token_index + 1}")
            return True
        return False
    
    def get_realtime_pe(self, ts_code: str, max_retries: int = 3) -> Optional[float]:
        """è·å–å®æ—¶PEæ•°æ®"""
        if not self.pro:
            return None
            
        for attempt in range(max_retries):
            try:
                # è·å–åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…å«PE_TTM
                df = self.pro.daily_basic(ts_code=ts_code, trade_date='', fields='ts_code,pe_ttm')
                
                if not df.empty and pd.notna(df.iloc[0]['pe_ttm']):
                    pe = float(df.iloc[0]['pe_ttm'])
                    if pe > 0:  # ç¡®ä¿PEä¸ºæ­£æ•°
                        logger.debug(f"è·å–{ts_code}å®æ—¶PE: {pe:.2f}")
                        return pe
                
                return None
                
            except Exception as e:
                logger.warning(f"è·å–{ts_code}å®æ—¶PEå¤±è´¥ (å°è¯•{attempt+1}/{max_retries}): {e}")
                
                # å¦‚æœæ˜¯APIé™åˆ¶ç›¸å…³é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢token
                if any(keyword in str(e).lower() for keyword in ['limit', 'timeout', 'rate', 'é™åˆ¶']):
                    if self.switch_token():
                        time.sleep(1)  # åˆ‡æ¢åç¨ä½œç­‰å¾…
                        continue
                
                # å¦åˆ™ç­‰å¾…åé‡è¯•
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2 + random.uniform(0.5, 1.5)
                    time.sleep(wait_time)
        
        return None

class ValueInvestmentAgent:
    """
    ä»·å€¼æŠ•èµ„Agent
    èåˆä¸‰ä½æŠ•èµ„å¤§å¸ˆçš„ç†å¿µï¼š
    - å·´è²ç‰¹ï¼šå¯»æ‰¾æŠ¤åŸæ²³ã€é•¿æœŸä»·å€¼ã€åˆç†ä»·æ ¼
    - æŸ¥ç†èŠ’æ ¼ï¼šç†æ€§æ€ç»´ã€è´¨é‡ä¼˜å…ˆã€åå‘æ€è€ƒ
    - æ ¼é›·å„å§†ï¼šå®‰å…¨è¾¹é™…ã€ä»·å€¼ä¸ä»·æ ¼å·®å¼‚ã€åŸºæœ¬é¢åˆ†æ
    
    æ”¯æŒå®æ—¶PEè·å–ã€æ™ºèƒ½ç­›é€‰å’ŒDeepSeek AIæ·±åº¦åˆ†æ
    """
    
    def __init__(self, db_path='stock_analysis.db', tushare_config_path='config.json'):
        self.db_path = db_path
        self.tushare_manager = None
        self.deepseek_analyzer = None
        self.setup_logger()
        self.load_tushare_config(tushare_config_path)
        self.load_deepseek_config(tushare_config_path)
        
    def setup_logger(self):
        """è®¾ç½®æ—¥å¿—"""
        logger.add(
            "logs/value_investment_{time}.log",
            rotation="10 MB",
            encoding="utf-8"
        )
    
    def load_tushare_config(self, config_path: str):
        """åŠ è½½Tushareé…ç½®"""
        tokens = []
        
        # å°è¯•ä»JSONé…ç½®æ–‡ä»¶åŠ è½½
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                tokens = config.get('tushare_tokens', [])
        except FileNotFoundError:
            logger.debug(f"æœªæ‰¾åˆ°JSONé…ç½®æ–‡ä»¶{config_path}")
        except Exception as e:
            logger.warning(f"è¯»å–JSONé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # å¦‚æœJSONé…ç½®ä¸ºç©ºï¼Œå°è¯•ä»config.pyåŠ è½½
        if not tokens:
            try:
                import config
                tokens = getattr(config, 'TUSHARE_TOKENS', [])
                if tokens:
                    logger.info("ä»config.pyåŠ è½½Tushareé…ç½®")
            except ImportError:
                logger.debug("æœªæ‰¾åˆ°config.pyæ¨¡å—")
            except Exception as e:
                logger.warning(f"ä»config.pyåŠ è½½é…ç½®å¤±è´¥: {e}")
        
        if tokens and TUSHARE_AVAILABLE:
            self.tushare_manager = TushareManager(tokens)
            logger.info(f"å·²åŠ è½½{len(tokens)}ä¸ªTushare token")
        else:
            logger.warning("æœªé…ç½®Tushare tokensæˆ–tushareä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å†å²PEæ•°æ®")
    
    def load_deepseek_config(self, config_path: str):
        """åŠ è½½DeepSeeké…ç½®"""
        deepseek_key = None
        api_url = "https://api.deepseek.com"  # é»˜è®¤URL
        model_name = "deepseek-ai/DeepSeek-R1"  # é»˜è®¤æ¨¡å‹åç§°
        
        # å°è¯•ä»JSONé…ç½®æ–‡ä»¶åŠ è½½
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                deepseek_key = config.get('deepseek_api_key')
                api_url = config.get('api_url', api_url)
                model_name = config.get('model_name', model_name)
        except FileNotFoundError:
            logger.debug(f"æœªæ‰¾åˆ°JSONé…ç½®æ–‡ä»¶{config_path}")
        except Exception as e:
            logger.warning(f"è¯»å–JSONé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # å¦‚æœJSONé…ç½®ä¸ºç©ºï¼Œå°è¯•ä»config.pyåŠ è½½
        if not deepseek_key:
            try:
                import config
                deepseek_key = getattr(config, 'DEEPSEEK_API_KEY', '')
                api_url = getattr(config, 'API_URL', api_url)
                model_name = getattr(config, 'DEEPSEEK_MODEL', model_name)
                if deepseek_key:
                    logger.info("ä»config.pyåŠ è½½DeepSeeké…ç½®")
            except ImportError:
                logger.debug("æœªæ‰¾åˆ°config.pyæ¨¡å—")
            except Exception as e:
                logger.warning(f"ä»config.pyåŠ è½½é…ç½®å¤±è´¥: {e}")
        
        if deepseek_key:
            self.deepseek_analyzer = DeepSeekAnalyzer(api_key=deepseek_key, base_url=api_url, model=model_name)
            logger.info(f"å·²åŠ è½½DeepSeek APIé…ç½® (URL: {api_url}, Model: {model_name})")
        else:
            logger.warning("æœªé…ç½®DeepSeek API keyï¼Œå°†è·³è¿‡AIåˆ†æ")
    
    def normalize_stock_code(self, stock_code: str) -> str:
        """æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼ï¼Œæ”¯æŒæ•°æ®åº“æŸ¥è¯¢"""
        # å¦‚æœå·²ç»æ˜¯å®Œæ•´æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if '.' in stock_code:
            return stock_code
        
        # 6ä½ä»£ç ï¼Œæ·»åŠ äº¤æ˜“æ‰€åç¼€
        if len(stock_code) == 6:
            if stock_code.startswith(('60', '68')):
                return f"{stock_code}.SH"
            elif stock_code.startswith(('00', '30')):
                return f"{stock_code}.SZ"
        
        return stock_code
    
    def get_realtime_pe(self, stock_code: str) -> Optional[float]:
        """è·å–å®æ—¶PEæ•°æ®"""
        if not self.tushare_manager:
            return None
            
        ts_code = self.normalize_stock_code(stock_code)
        return self.tushare_manager.get_realtime_pe(ts_code)
    
    def _should_skip_stock(self, stock_code: str, stock_name: str) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ­¤è‚¡ç¥¨
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
        
        Returns:
            (æ˜¯å¦è·³è¿‡, è·³è¿‡åŸå› )
        """
        # 1. è·³è¿‡STè‚¡ç¥¨
        if stock_name and ('ST' in stock_name or '*ST' in stock_name or 'PT' in stock_name):
            return True, "STè‚¡ç¥¨é£é™©è¿‡é«˜"
        
        # 2. è·³è¿‡Bè‚¡
        if stock_code.endswith('.BJ'):  # åŒ—äº¤æ‰€
            return True, "åŒ—äº¤æ‰€è‚¡ç¥¨æµåŠ¨æ€§è¾ƒä½"
        
        # 3. æ£€æŸ¥è¿ç»­äºæŸ
        conn = sqlite3.connect(self.db_path)
        try:
            # è·å–æœ€è¿‘3å¹´çš„å‡€åˆ©æ¶¦æ•°æ®
            query = """
            SELECT year, metric_value 
            FROM financial_metrics 
            WHERE stock_code = ? AND metric_name = 'net_profit'
            ORDER BY year DESC
            LIMIT 3
            """
            df = pd.read_sql_query(query, conn, params=[stock_code])
            
            if len(df) >= 3:
                # æ£€æŸ¥æ˜¯å¦è¿ç»­3å¹´äºæŸ
                recent_profits = df['metric_value'].tolist()
                if all(profit <= 0 for profit in recent_profits if pd.notna(profit)):
                    return True, "è¿ç»­3å¹´äºæŸ"
            
            # 4. æ£€æŸ¥æ˜¯å¦æœ‰åŸºæœ¬è´¢åŠ¡æ•°æ®
            basic_metrics_query = """
            SELECT COUNT(DISTINCT metric_name) as metric_count
            FROM financial_metrics 
            WHERE stock_code = ? AND metric_name IN ('roe', 'pe', 'pb')
            """
            metric_count_df = pd.read_sql_query(basic_metrics_query, conn, params=[stock_code])
            
            if metric_count_df.iloc[0]['metric_count'] < 2:  # è‡³å°‘è¦æœ‰2ä¸ªåŸºæœ¬æŒ‡æ ‡
                return True, "ç¼ºä¹åŸºæœ¬è´¢åŠ¡æ•°æ®"
            
            # 5. æ£€æŸ¥ROEæ•°æ®è´¨é‡
            roe_query = """
            SELECT metric_value 
            FROM financial_metrics 
            WHERE stock_code = ? AND metric_name = 'roe'
            ORDER BY year DESC
            LIMIT 3
            """
            roe_df = pd.read_sql_query(roe_query, conn, params=[stock_code])
            
            if len(roe_df) >= 2:
                # å¦‚æœæœ€è¿‘2å¹´ROEéƒ½æ˜¯è´Ÿæ•°ï¼Œè·³è¿‡
                recent_roe = roe_df['metric_value'].tolist()
                valid_roe = [roe for roe in recent_roe if pd.notna(roe)]
                if len(valid_roe) >= 2 and all(roe < 0 for roe in valid_roe):
                    return True, "è¿‘å¹´ROEæŒç»­ä¸ºè´Ÿ"
            
            return False, ""
            
        except Exception as e:
            logger.warning(f"ç­›é€‰è‚¡ç¥¨{stock_code}æ—¶å‡ºé”™: {e}")
            return False, ""
        finally:
            conn.close()
    
    def get_stock_metrics(self, stock_code: str, years: List[int] = None) -> Dict:
        """è·å–å•ä¸ªè‚¡ç¥¨çš„è´¢åŠ¡æŒ‡æ ‡"""
        if years is None:
            years = [2020, 2021, 2022, 2023, 2024]
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        normalized_code = self.normalize_stock_code(stock_code)
        
        conn = sqlite3.connect(self.db_path)
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        basic_info = pd.read_sql_query(
            "SELECT * FROM stocks WHERE stock_code = ?", 
            conn, params=[normalized_code]
        )
        
        if basic_info.empty:
            conn.close()
            return {}
        
        # è·å–è´¢åŠ¡æŒ‡æ ‡
        metrics_data = pd.read_sql_query(
            "SELECT year, metric_name, metric_value FROM financial_metrics WHERE stock_code = ?",
            conn, params=[normalized_code]
        )
        
        conn.close()
        
        if metrics_data.empty:
            return {}
        
        # é‡æ„æ•°æ®æ ¼å¼
        result = {
            'basic_info': basic_info.iloc[0].to_dict(),
            'metrics': {}
        }
        
        for _, row in metrics_data.iterrows():
            year = int(row['year'])
            metric = row['metric_name']
            value = row['metric_value']
            
            if metric not in result['metrics']:
                result['metrics'][metric] = {}
            result['metrics'][metric][year] = value
            
        return result
    
    def buffett_criteria(self, stock_data: Dict, include_pe_evaluation: bool = False, realtime_pe: Optional[float] = None) -> Dict:
        """
        å·´è²ç‰¹é€‰è‚¡æ ‡å‡†
        - æŒç»­é«˜ROE (>15%)
        - ç¨³å®šç›ˆåˆ©å¢é•¿
        - ä½å€ºåŠ¡æ¯”ç‡ (<0.3)
        - åˆç†ä¼°å€¼
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            include_pe_evaluation: æ˜¯å¦åŒ…å«PEè¯„ä¼°
            realtime_pe: å®æ—¶PEæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        """
        score = 0
        details = []
        
        metrics = stock_data.get('metrics', {})
        
        # 1. ROEåˆ†æ - å·´è²ç‰¹æœ€çœ‹é‡çš„æŒ‡æ ‡
        roe_data = metrics.get('roe', {})
        if roe_data:
            roe_values = [v for v in roe_data.values() if v is not None and v > 0]
            if len(roe_values) >= 3:
                avg_roe = np.mean(roe_values)  # ä¿æŒç™¾åˆ†æ¯”å½¢å¼ç”¨äºæ˜¾ç¤º
                # è½¬æ¢ä¸ºå°æ•°è¿›è¡Œæ¯”è¾ƒ
                avg_roe_decimal = avg_roe / 100.0
                if avg_roe_decimal > 0.20:
                    score += 25
                    details.append(f"ğŸŒŸ å“è¶ŠROE: {avg_roe:.1f}% (>20%)")
                elif avg_roe_decimal > 0.15:
                    score += 15
                    details.append(f"âœ… ä¼˜ç§€ROE: {avg_roe:.1f}% (>15%)")
                elif avg_roe_decimal > 0.10:
                    score += 5
                    details.append(f"ğŸ“Š ä¸€èˆ¬ROE: {avg_roe:.1f}% (>10%)")
                
                # ROEç¨³å®šæ€§
                roe_std = np.std(roe_values)
                if roe_std < 5:
                    score += 10
                    details.append(f"ğŸ¯ ROEç¨³å®šæ€§è‰¯å¥½ (æ ‡å‡†å·®: {roe_std:.1f})")
        
        # 2. å€ºåŠ¡æ¯”ç‡åˆ†æ
        debt_data = metrics.get('debt_ratio', {})
        if debt_data:
            debt_values = [v for v in debt_data.values() if v is not None]
            if debt_values:
                avg_debt = np.mean(debt_values) / 100.0
                if avg_debt < 0.2:
                    score += 20
                    details.append(f"ğŸ’ª ä½å€ºåŠ¡è´Ÿæ‹…: {avg_debt:.1%} (<20%)")
                elif avg_debt < 0.3:
                    score += 10
                    details.append(f"âœ… é€‚åº¦å€ºåŠ¡: {avg_debt:.1%} (<30%)")
                elif avg_debt > 0.6:
                    score -= 10
                    details.append(f"âš ï¸ é«˜å€ºåŠ¡é£é™©: {avg_debt:.1%} (>60%)")
        
        # 3. ç›ˆåˆ©ç¨³å®šæ€§ï¼ˆå‡€åˆ©ç‡ï¼‰
        net_margin_data = metrics.get('net_margin', {})
        if net_margin_data:
            margin_values = [v for v in net_margin_data.values() if v is not None]
            positive_margins = [v for v in margin_values if v > 0]
            
            if len(positive_margins) == len(margin_values) and len(margin_values) >= 3:
                score += 15
                avg_margin = np.mean(positive_margins)
                details.append(f"ğŸ“ˆ æŒç»­ç›ˆåˆ©: å‡€åˆ©ç‡ {avg_margin:.1f}%")
        
        # 4. æµåŠ¨æ€§åˆ†æ
        current_ratio_data = metrics.get('current_ratio', {})
        if current_ratio_data:
            cr_values = [v for v in current_ratio_data.values() if v is not None]
            if cr_values:
                avg_cr = np.mean(cr_values)
                if avg_cr > 2:
                    score += 10
                    details.append(f"ğŸ’° æµåŠ¨æ€§å……è£•: {avg_cr:.1f}")
                elif avg_cr > 1.5:
                    score += 5
                    details.append(f"âœ… æµåŠ¨æ€§è‰¯å¥½: {avg_cr:.1f}")
        
        # 5. PEä¼°å€¼åˆ†æï¼ˆå¯é€‰ï¼‰
        if include_pe_evaluation:
            current_pe = realtime_pe
            pe_source = "å®æ—¶"
            
            # å¦‚æœæ²¡æœ‰å®æ—¶PEï¼Œä½¿ç”¨å†å²PE
            if current_pe is None:
                pe_data = metrics.get('pe', {})
                if pe_data:
                    latest_year = max(pe_data.keys())
                    current_pe = pe_data[latest_year]
                    pe_source = "å†å²"
            
            if current_pe is not None and 0 < current_pe < 100:
                if current_pe < 15:
                    score += 25
                    details.append(f"ğŸ’ ä½ä¼°å€¼: PE {current_pe:.1f}x (<15, {pe_source})")
                elif current_pe < 25:
                    score += 15
                    details.append(f"âœ… åˆç†ä¼°å€¼: PE {current_pe:.1f}x (<25, {pe_source})")
                elif current_pe < 35:
                    score += 5
                    details.append(f"ğŸ“Š é€‚ä¸­ä¼°å€¼: PE {current_pe:.1f}x (<35, {pe_source})")
                elif current_pe > 50:
                    score -= 10
                    details.append(f"âš ï¸ ä¼°å€¼åé«˜: PE {current_pe:.1f}x (>50, {pe_source})")
        
        return {
            'score': min(score, 100),
            'details': details,
            'methodology': 'å·´è²ç‰¹æ ‡å‡†ï¼šæŠ¤åŸæ²³ã€æŒç»­ç›ˆåˆ©ã€ä½å€ºåŠ¡' + ('ã€åˆç†ä¼°å€¼' if include_pe_evaluation else '')
        }
    
    def munger_criteria(self, stock_data: Dict, include_pe_evaluation: bool = False, realtime_pe: Optional[float] = None) -> Dict:
        """
        èŠ’æ ¼é€‰è‚¡æ ‡å‡†
        - ç®€å•æ˜“æ‡‚çš„ç”Ÿæ„æ¨¡å¼
        - è´¨é‡ä¼˜äºä»·æ ¼
        - ç†æ€§åˆ†æï¼Œé¿å…æƒ…ç»ªåŒ–
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            include_pe_evaluation: æ˜¯å¦åŒ…å«PEè¯„ä¼°
            realtime_pe: å®æ—¶PEæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        """
        score = 0
        details = []
        
        metrics = stock_data.get('metrics', {})
        industry = stock_data.get('basic_info', {}).get('industry', '')
        
        # 1. è¡Œä¸šè´¨é‡è¯„ä¼°ï¼ˆèŠ’æ ¼åå¥½çš„è¡Œä¸šï¼‰
        quality_industries = [
            'é“¶è¡Œ', 'ä¿é™©', 'é£Ÿå“é¥®æ–™', 'ç™½é…’', 'åŒ»è¯ç”Ÿç‰©', 'å…¬ç”¨äº‹ä¸š',
            'æ¶ˆè´¹æœåŠ¡', 'å•†ä¸šè´¸æ˜“', 'å®¶ç”¨ç”µå™¨', 'é¤é¥®', 'ä¹³åˆ¶å“', 
            'è°ƒå‘³å“', 'è½¯é¥®æ–™', 'é…¿é…’', 'ä¸­è¯', 'ç”Ÿç‰©åˆ¶è¯', 'åŒ»ç–—å™¨æ¢°',
            'ç”µåŠ›', 'ç‡ƒæ°”', 'æ°´åŠ¡', 'æœºåœº', 'é«˜é€Ÿå…¬è·¯', 'æ¸¯å£'
        ]
        
        if any(keyword in industry for keyword in quality_industries):
            score += 15
            details.append(f"ğŸ¯ ä¼˜è´¨è¡Œä¸š: {industry}")
        
        # 2. èµ„äº§å‘¨è½¬ç‡ï¼ˆç»è¥æ•ˆç‡ï¼‰
        asset_turnover_data = metrics.get('asset_turnover', {})
        if asset_turnover_data:
            at_values = [v for v in asset_turnover_data.values() if v is not None and v > 0]
            if at_values:
                avg_turnover = np.mean(at_values)
                if avg_turnover > 0.8:
                    score += 15
                    details.append(f"âš¡ é«˜æ•ˆè¿è¥: èµ„äº§å‘¨è½¬ç‡ {avg_turnover:.2f}")
                elif avg_turnover > 0.5:
                    score += 10
                    details.append(f"âœ… è¿è¥è‰¯å¥½: èµ„äº§å‘¨è½¬ç‡ {avg_turnover:.2f}")
        
        # 3. æ¯›åˆ©ç‡ç¨³å®šæ€§ï¼ˆäº§å“å®šä»·æƒï¼‰
        gross_margin_data = metrics.get('gross_margin', {})
        if gross_margin_data:
            gm_values = [v for v in gross_margin_data.values() if v is not None and v > 0]
            if len(gm_values) >= 3:
                avg_gm = np.mean(gm_values)  # ä¿æŒç™¾åˆ†æ¯”å½¢å¼ç”¨äºæ˜¾ç¤º
                gm_trend = self._calculate_trend(gm_values)
                
                # è½¬æ¢ä¸ºå°æ•°è¿›è¡Œæ¯”è¾ƒ
                avg_gm_decimal = avg_gm / 100.0
                if avg_gm_decimal > 0.40:
                    score += 20
                    details.append(f"ğŸ’ é«˜æ¯›åˆ©ç‡: {avg_gm:.1f}% (å¼ºå®šä»·æƒ)")
                elif avg_gm_decimal > 0.25:
                    score += 10
                    details.append(f"âœ… è‰¯å¥½æ¯›åˆ©ç‡: {avg_gm:.1f}%")
                
                if gm_trend > 0:
                    score += 10
                    details.append("ğŸ“ˆ æ¯›åˆ©ç‡å‘ˆä¸Šå‡è¶‹åŠ¿")
        
        # 4. åå‘æ€ç»´ï¼šé¿å¼€é«˜ä¼°å€¼é™·é˜±ï¼ˆå¯é€‰ï¼‰
        if include_pe_evaluation:
            current_pe = realtime_pe
            pe_source = "å®æ—¶"
            
            # å¦‚æœæ²¡æœ‰å®æ—¶PEï¼Œä½¿ç”¨å†å²PE
            if current_pe is None:
                pe_data = metrics.get('pe', {})
                if pe_data:
                    latest_year = max(pe_data.keys())
                    current_pe = pe_data[latest_year]
                    pe_source = "å†å²"
            
            if current_pe is not None and 0 < current_pe < 100:
                if current_pe < 20:
                    score += 15
                    details.append(f"ğŸ’° åˆç†ä¼°å€¼: PE {current_pe:.1f}x (<20, {pe_source})")
                elif current_pe < 30:
                    score += 5
                    details.append(f"ğŸ“Š é€‚ä¸­ä¼°å€¼: PE {current_pe:.1f}x (<30, {pe_source})")
                elif current_pe > 60:
                    score -= 10
                    details.append(f"âš ï¸ ä¼°å€¼åé«˜: PE {current_pe:.1f}x (>60, {pe_source})")
        
        return {
            'score': min(score, 100),
            'details': details,
            'methodology': 'èŠ’æ ¼æ ‡å‡†ï¼šè´¨é‡ä¼˜å…ˆã€ç†æ€§åˆ†æã€é•¿æœŸè§†è§’' + ('ã€åå‘æ€ç»´' if include_pe_evaluation else '')
        }
    
    def graham_criteria(self, stock_data: Dict, include_pe_evaluation: bool = True, realtime_pe: Optional[float] = None) -> Dict:
        """
        æ ¼é›·å„å§†é€‰è‚¡æ ‡å‡†
        - å®‰å…¨è¾¹é™…
        - ä»·å€¼æŠ•èµ„çš„é¼»ç¥–ç†å¿µ
        - é‡è§†èµ„äº§è´Ÿå€ºè¡¨
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            include_pe_evaluation: æ˜¯å¦åŒ…å«PEè¯„ä¼°ï¼ˆæ ¼é›·å„å§†é»˜è®¤åŒ…å«ï¼‰
            realtime_pe: å®æ—¶PEæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        """
        score = 0
        details = []
        
        metrics = stock_data.get('metrics', {})
        
        # 1. PEæ¯”ç‡ï¼ˆæ ¼é›·å„å§†ç»å…¸æŒ‡æ ‡ï¼‰
        if include_pe_evaluation:
            current_pe = realtime_pe
            pe_source = "å®æ—¶"
            
            # å¦‚æœæ²¡æœ‰å®æ—¶PEï¼Œä½¿ç”¨å†å²PE
            if current_pe is None:
                pe_data = metrics.get('pe', {})
                if pe_data:
                    latest_year = max(pe_data.keys())
                    current_pe = pe_data[latest_year]
                    pe_source = "å†å²"
            
            if current_pe is not None and 0 < current_pe < 100:
                if current_pe < 12:
                    score += 25
                    details.append(f"ğŸ¯ ä½ä¼°å€¼: PE {current_pe:.1f}x (<12, {pe_source})")
                elif current_pe < 20:
                    score += 15
                    details.append(f"âœ… åˆç†ä¼°å€¼: PE {current_pe:.1f}x (<20, {pe_source})")
                elif current_pe < 30:
                    score += 5
                    details.append(f"ğŸ“Š é€‚ä¸­ä¼°å€¼: PE {current_pe:.1f}x (<30, {pe_source})")
                elif current_pe > 40:
                    score -= 5
                    details.append(f"âš ï¸ ä¼°å€¼åé«˜: PE {current_pe:.1f}x (>40, {pe_source})")
        
        # 2. PBæ¯”ç‡ï¼ˆèµ„äº§ä»·å€¼ï¼‰
        pb_data = metrics.get('pb', {})
        if pb_data:
            # ä½¿ç”¨æœ€æ–°å¹´ä»½çš„PBæ•°æ®
            latest_year = max(pb_data.keys())
            current_pb = pb_data[latest_year]
            
            if current_pb is not None and current_pb > 0:
                if current_pb < 1:
                    score += 20
                    details.append(f"ğŸ’ ç ´å‡€è‚¡: PB {current_pb:.2f}x (<1)")
                elif current_pb < 2:
                    score += 10
                    details.append(f"âœ… ä½PB: {current_pb:.2f}x (<2)")
                elif current_pb < 3:
                    score += 5
                    details.append(f"ğŸ“Š åˆç†PB: {current_pb:.2f}x (<3)")
        
        # 3. è‚¡æ¯ç‡ï¼ˆä»·å€¼å›æŠ¥ï¼‰
        dividend_data = metrics.get('dividend', {})
        if dividend_data:
            # ä½¿ç”¨æœ€æ–°å¹´ä»½çš„è‚¡æ¯ç‡æ•°æ®
            latest_year = max(dividend_data.keys())
            current_dividend = dividend_data[latest_year]
            
            if current_dividend is not None and current_dividend > 0:
                # è½¬æ¢ä¸ºå°æ•°è¿›è¡Œæ¯”è¾ƒ
                current_dividend_decimal = current_dividend / 100.0
                if current_dividend_decimal > 0.04:
                    score += 15
                    details.append(f"ğŸ’° é«˜è‚¡æ¯: {current_dividend:.1f}% (>4%)")
                elif current_dividend_decimal > 0.02:
                    score += 10
                    details.append(f"âœ… è‰¯å¥½è‚¡æ¯: {current_dividend:.1f}% (>2%)")
        
        # 4. æµåŠ¨æ¯”ç‡ï¼ˆå®‰å…¨è¾¹é™…ï¼‰
        current_ratio_data = metrics.get('current_ratio', {})
        if current_ratio_data:
            cr_values = [v for v in current_ratio_data.values() if v is not None]
            if cr_values:
                avg_cr = np.mean(cr_values)
                if avg_cr > 2:
                    score += 15
                    details.append(f"ğŸ›¡ï¸ å®‰å…¨è¾¹é™…é«˜: æµåŠ¨æ¯”ç‡ {avg_cr:.1f}")
                elif avg_cr > 1.5:
                    score += 10
                    details.append(f"âœ… å®‰å…¨è¾¹é™…é€‚ä¸­: æµåŠ¨æ¯”ç‡ {avg_cr:.1f}")
        
        # 5. æ€»èµ„äº§å¢é•¿ï¼ˆä¼ä¸šå‘å±•ï¼‰
        total_assets_data = metrics.get('total_assets', {})
        if total_assets_data:
            asset_values = [v for v in total_assets_data.values() if v is not None and v > 0]
            if len(asset_values) >= 3:
                asset_growth = self._calculate_growth_rate(asset_values)
                if asset_growth > 0.1:
                    score += 10
                    details.append(f"ğŸ“ˆ èµ„äº§ç¨³å¥å¢é•¿: {asset_growth:.1%}")
                elif asset_growth > 0:
                    score += 5
                    details.append(f"âœ… èµ„äº§æ­£å¢é•¿: {asset_growth:.1%}")
        
        return {
            'score': min(score, 100),
            'details': details,
            'methodology': 'æ ¼é›·å„å§†æ ‡å‡†ï¼šå®‰å…¨è¾¹é™…ã€ä»·å€¼å‘ç°ã€åŸºæœ¬é¢åˆ†æ' + ('ã€PEä¼°å€¼' if include_pe_evaluation else '')
        }
    
    def preliminary_screening(self, stock_code: str) -> Dict:
        """
        åŸºäºå†å²æ•°æ®çš„åˆæ­¥ç­›é€‰è¯„åˆ†ï¼ˆä¸ä½¿ç”¨å®æ—¶PEï¼‰
        ä¸»è¦ç”¨äºç¬¬ä¸€é˜¶æ®µå¿«é€Ÿç­›é€‰
        """
        try:
            stock_data = self.get_stock_metrics(stock_code)
            
            if not stock_data:
                return {'error': f'æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„æ•°æ®'}
            
            metrics = stock_data.get('metrics', {})
            preliminary_score = 0
            
            # ROEè¯„åˆ† (15åˆ†)
            roe_data = metrics.get('roe', {})
            if roe_data:
                roe_values = [v for v in roe_data.values() if v is not None]
                if roe_values:
                    roe_avg = np.mean(roe_values) / 100.0  # è½¬æ¢ä¸ºå°æ•°
                    if roe_avg >= 0.15:  # â‰¥15%
                        preliminary_score += 15
                    elif roe_avg >= 0.10:  # 10-15%
                        preliminary_score += 10
                    elif roe_avg >= 0.05:  # 5-10%
                        preliminary_score += 5
            
            # ç°é‡‘æµè¯„åˆ† (10åˆ†)
            cf_data = metrics.get('operating_cash_flow', {})
            if cf_data:
                cf_count = sum(1 for v in cf_data.values() if v and v > 0)
                if cf_count >= 4:  # 4å¹´éƒ½ä¸ºæ­£
                    preliminary_score += 10
                elif cf_count >= 3:  # 3å¹´ä¸ºæ­£
                    preliminary_score += 7
                elif cf_count >= 2:  # 2å¹´ä¸ºæ­£
                    preliminary_score += 3
            
            # è¥æ”¶å¢é•¿è¯„åˆ† (10åˆ†)
            revenue_data = metrics.get('revenue', {})
            avg_growth = None
            if revenue_data:
                revenue_values = [v for v in revenue_data.values() if v is not None and v > 0]
                if len(revenue_values) >= 3:
                    growth_rates = []
                    for i in range(1, len(revenue_values)):
                        if revenue_values[i-1] > 0:
                            growth = (revenue_values[i] - revenue_values[i-1]) / revenue_values[i-1]
                            growth_rates.append(growth)
                    
                    if growth_rates:
                        avg_growth = np.mean(growth_rates)
                        if avg_growth >= 0.10:  # â‰¥10%
                            preliminary_score += 10
                        elif avg_growth >= 0.05:  # 5-10%
                            preliminary_score += 7
                        elif avg_growth >= 0:  # æ­£å¢é•¿
                            preliminary_score += 3
            
            # è´¢åŠ¡ç¨³å®šæ€§è¯„åˆ† (10åˆ†)
            debt_data = metrics.get('debt_ratio', {})
            current_data = metrics.get('current_ratio', {})
            
            debt_ratio = None
            current_ratio = None
            
            if debt_data:
                debt_values = [v for v in debt_data.values() if v is not None]
                if debt_values:
                    debt_ratio = np.mean(debt_values) / 100.0  # è½¬æ¢ä¸ºå°æ•°
                    if debt_ratio < 0.3:  # è´Ÿå€ºç‡<30%
                        preliminary_score += 5
                    elif debt_ratio < 0.5:  # è´Ÿå€ºç‡<50%
                        preliminary_score += 3
            
            if current_data:
                current_values = [v for v in current_data.values() if v is not None]
                if current_values:
                    current_ratio = np.mean(current_values)
                    if current_ratio > 1.5:  # æµåŠ¨æ¯”ç‡>1.5
                        preliminary_score += 5
                    elif current_ratio > 1.0:  # æµåŠ¨æ¯”ç‡>1.0
                        preliminary_score += 3
            
            # å†å²PEè¯„åˆ† (ä½¿ç”¨æ•°æ®åº“ä¸­çš„å†å²PEï¼Œä¸è°ƒç”¨API)
            pe_data = metrics.get('pe', {})
            historical_pe = None
            if pe_data:
                pe_values = [v for v in pe_data.values() if v is not None and v > 0]
                if pe_values:
                    historical_pe = np.mean(pe_values)  # å–å¹³å‡å†å²PE
                    if historical_pe <= 10:
                        preliminary_score += 15
                    elif historical_pe <= 15:
                        preliminary_score += 12
                    elif historical_pe <= 20:
                        preliminary_score += 8
                    elif historical_pe <= 30:
                        preliminary_score += 5
            
            return {
                'stock_code': stock_code,
                'stock_name': stock_data['basic_info'].get('stock_name', ''),
                'preliminary_score': preliminary_score,
                'historical_pe': historical_pe,
                'roe_avg': roe_avg * 100 if 'roe_avg' in locals() and roe_avg else None,
                'revenue_growth': avg_growth,
                'debt_ratio': debt_ratio * 100 if debt_ratio else None,
                'current_ratio': current_ratio
            }
            
        except Exception as e:
            logger.error(f"åˆæ­¥ç­›é€‰è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            return {'error': str(e)}
    
    def _assess_potential(self, stock_code: str, preliminary_result: Dict) -> float:
        """
        è¯„ä¼°è‚¡ç¥¨æ½œåŠ›åˆ†æ•°
        åŸºäºå¤šä¸ªç»´åº¦ç»™å‡ºæ½œåŠ›è¯„ä¼°ï¼Œç”¨äºä¼˜å…ˆçº§æ’åº
        """
        potential_score = 0
        
        try:
            # ROEç¨³å®šæ€§å’Œè¶‹åŠ¿ (æœ€é«˜15åˆ†)
            stock_data = self.get_stock_metrics(stock_code)
            if not stock_data:
                return 0
                
            metrics = stock_data.get('metrics', {})
            roe_data = metrics.get('roe', {})
            
            if roe_data:
                roe_values = [v for v in roe_data.values() if v is not None]
                
                if len(roe_values) >= 3:
                    # ROEç¨³å®šæ€§ (å‰é¢å‡ å¹´çš„ROEæ³¢åŠ¨)
                    roe_std = np.std(roe_values)
                    if roe_std < 2:  # æ ‡å‡†å·®<2%ï¼Œéå¸¸ç¨³å®š
                        potential_score += 8
                    elif roe_std < 5:  # æ ‡å‡†å·®<5%ï¼Œè¾ƒç¨³å®š
                        potential_score += 5
                    elif roe_std < 8:  # æ ‡å‡†å·®<8%ï¼Œä¸€èˆ¬ç¨³å®š
                        potential_score += 2
                    
                    # ROEè¶‹åŠ¿ (æ˜¯å¦ä¸Šå‡è¶‹åŠ¿)
                    if len(roe_values) >= 3:
                        recent_roe = np.mean(roe_values[-2:])  # æœ€è¿‘2å¹´å¹³å‡
                        early_roe = np.mean(roe_values[:2])   # æ—©æœŸ2å¹´å¹³å‡
                        if recent_roe > early_roe * 1.1:  # æœ€è¿‘æ¯”æ—©æœŸé«˜10%+
                            potential_score += 7
                        elif recent_roe > early_roe:  # ä¸Šå‡è¶‹åŠ¿
                            potential_score += 4
            
            # è¥æ”¶è´¨é‡å’Œå¢é•¿ä¸€è‡´æ€§ (æœ€é«˜10åˆ†)
            revenue_data = metrics.get('revenue', {})
            if revenue_data:
                revenue_values = [v for v in revenue_data.values() if v is not None and v > 0]
                if len(revenue_values) >= 3:
                    # è¥æ”¶å¢é•¿ä¸€è‡´æ€§ (è¿ç»­å¢é•¿å¹´æ•°)
                    growth_count = 0
                    for i in range(1, len(revenue_values)):
                        if revenue_values[i] > revenue_values[i-1]:
                            growth_count += 1
                    
                    if growth_count == len(revenue_values) - 1:  # è¿ç»­å¢é•¿
                        potential_score += 8
                    elif growth_count >= len(revenue_values) * 0.7:  # 70%å¹´ä»½å¢é•¿
                        potential_score += 5
                    elif growth_count >= len(revenue_values) * 0.5:  # 50%å¹´ä»½å¢é•¿
                        potential_score += 2
            
            # ç°é‡‘æµè´¨é‡ (æœ€é«˜8åˆ†)
            cf_data = metrics.get('operating_cash_flow', {})
            if cf_data:
                cf_values = [v for v in cf_data.values() if v is not None]
                if cf_values:
                    positive_cf_ratio = sum(1 for v in cf_values if v > 0) / len(cf_values)
                    if positive_cf_ratio >= 0.8:  # 80%ä»¥ä¸Šå¹´ä»½ä¸ºæ­£
                        potential_score += 8
                    elif positive_cf_ratio >= 0.6:  # 60%ä»¥ä¸Šå¹´ä»½ä¸ºæ­£
                        potential_score += 5
                    elif positive_cf_ratio >= 0.4:  # 40%ä»¥ä¸Šå¹´ä»½ä¸ºæ­£
                        potential_score += 2
            
            # è´¢åŠ¡å®‰å…¨è¾¹é™… (æœ€é«˜7åˆ†)
            debt_data = metrics.get('debt_ratio', {})
            current_data = metrics.get('current_ratio', {})
            
            debt_ratio = 1.0  # é»˜è®¤å€¼
            current_ratio = 0.5  # é»˜è®¤å€¼
            
            if debt_data:
                debt_values = [v for v in debt_data.values() if v is not None]
                if debt_values:
                    debt_ratio = np.mean(debt_values) / 100.0
            
            if current_data:
                current_values = [v for v in current_data.values() if v is not None]
                if current_values:
                    current_ratio = np.mean(current_values)
            
            # æä½å€ºåŠ¡ç‡é¢å¤–åŠ åˆ†
            if debt_ratio < 0.2:
                potential_score += 4
            elif debt_ratio < 0.4:
                potential_score += 2
            
            # ä¼˜ç§€æµåŠ¨æ€§é¢å¤–åŠ åˆ†
            if current_ratio > 2.0:
                potential_score += 3
            elif current_ratio > 1.5:
                potential_score += 1
            
            # è¡Œä¸šç›¸å¯¹ä¼˜åŠ¿ (åŸºäºå†å²PEçš„åˆç†æ€§ï¼Œæœ€é«˜5åˆ†)
            historical_pe = preliminary_result.get('historical_pe')
            if historical_pe and 5 <= historical_pe <= 25:  # åˆç†PEèŒƒå›´
                if historical_pe <= 12:
                    potential_score += 5
                elif historical_pe <= 18:
                    potential_score += 3
                elif historical_pe <= 25:
                    potential_score += 1
            
            return min(potential_score, 50)  # æ½œåŠ›åˆ†æ•°ä¸Šé™50åˆ†
            
        except Exception as e:
            logger.error(f"è¯„ä¼°è‚¡ç¥¨ {stock_code} æ½œåŠ›æ—¶å‡ºé”™: {e}")
            return 0
    
    def comprehensive_evaluation(self, stock_code: str, use_realtime_pe: bool = True) -> Dict:
        """
        ç»¼åˆè¯„ä¼°è‚¡ç¥¨
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            use_realtime_pe: æ˜¯å¦ä½¿ç”¨å®æ—¶PEï¼ˆè°ƒç”¨Tushare APIï¼‰
        """
        try:
            stock_data = self.get_stock_metrics(stock_code)
            
            if not stock_data:
                return {'error': f'æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„æ•°æ®'}
            
            pe_api_used = False
            realtime_pe = None
            
            # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦è·å–å®æ—¶PE
            if use_realtime_pe:
                try:
                    realtime_pe = self.get_realtime_pe(stock_code)
                    if realtime_pe is not None:
                        pe_api_used = True
                        # ç”¨å®æ—¶PEæ›¿æ¢æ•°æ®ä¸­çš„å†å²PE
                        if 'metrics' not in stock_data:
                            stock_data['metrics'] = {}
                        if 'pe' not in stock_data['metrics']:
                            stock_data['metrics']['pe'] = {}
                        stock_data['metrics']['pe']['current'] = realtime_pe
                        logger.debug(f"ä½¿ç”¨å®æ—¶PE: {stock_code} PE={realtime_pe}")
                    else:
                        logger.debug(f"è·å–å®æ—¶PEå¤±è´¥ï¼Œä½¿ç”¨å†å²PE: {stock_code}")
                except Exception as e:
                    logger.warning(f"è·å–å®æ—¶PEå¤±è´¥ {stock_code}: {e}ï¼Œä½¿ç”¨å†å²PE")
            
            # ä¸‰ä½å¤§å¸ˆçš„è¯„åˆ†
            buffett_result = self.buffett_criteria(stock_data, include_pe_evaluation=True, realtime_pe=realtime_pe)
            munger_result = self.munger_criteria(stock_data, include_pe_evaluation=True, realtime_pe=realtime_pe)
            graham_result = self.graham_criteria(stock_data, include_pe_evaluation=True, realtime_pe=realtime_pe)
            
            # ç»¼åˆè¯„åˆ†
            total_score = (
                buffett_result['score'] * 0.4 +  # å·´è²ç‰¹æƒé‡40%
                munger_result['score'] * 0.3 +   # èŠ’æ ¼æƒé‡30%
                graham_result['score'] * 0.3     # æ ¼é›·å„å§†æƒé‡30%
            )
            
            # æŠ•èµ„ç­‰çº§
            if total_score >= 80:
                grade = "A+ å¼ºçƒˆæ¨è"
            elif total_score >= 70:
                grade = "A æ¨èä¹°å…¥"
            elif total_score >= 60:
                grade = "B+ å€¼å¾—å…³æ³¨"
            elif total_score >= 50:
                grade = "B è°¨æ…è§‚å¯Ÿ"
            else:
                grade = "C æš‚ä¸æ¨è"
            
            evaluation_result = {
                'stock_code': stock_code,
                'stock_name': stock_data['basic_info']['stock_name'],
                'industry': stock_data['basic_info']['industry'],
                'total_score': round(total_score, 1),
                'grade': grade,
                'buffett_analysis': buffett_result,
                'munger_analysis': munger_result,
                'graham_analysis': graham_result,
                'pe_api_used': pe_api_used,  # æ ‡è®°æ˜¯å¦ä½¿ç”¨äº†API
                'evaluation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # æ·»åŠ PEä¿¡æ¯
            if realtime_pe is not None:
                evaluation_result['realtime_pe'] = realtime_pe
            
            # æ·»åŠ å†å²PEä¿¡æ¯
            metrics = stock_data.get('metrics', {})
            pe_data = metrics.get('pe', {})
            if pe_data:
                pe_values = [v for v in pe_data.values() if v is not None and v > 0]
                if pe_values:
                    evaluation_result['pe_ratio'] = np.mean(pe_values)
            
            return evaluation_result
            
        except Exception as e:
            logger.error(f"ç»¼åˆè¯„ä¼°è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            return {'error': str(e)}
    
    def screen_value_stocks(self, min_score: float = 0, limit: int = None, preliminary_threshold: float = 0, test_mode: bool = False, test_count: int = 100) -> List[Dict]:
        """
        æ™ºèƒ½ç­›é€‰ä»·å€¼è‚¡ç¥¨ - ä¸¤é˜¶æ®µç­–ç•¥æé«˜å¬å›ç‡ï¼Œé™ä½APIè°ƒç”¨
        
        Args:
            min_score: æœ€ç»ˆæœ€ä½åˆ†æ•°ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            limit: æœ€ç»ˆç­›é€‰æ•°é‡é™åˆ¶ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            preliminary_threshold: åˆæ­¥ç­›é€‰é˜ˆå€¼ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            test_mode: æ˜¯å¦æµ‹è¯•æ¨¡å¼ï¼ˆåªåˆ†æå°‘é‡è‚¡ç¥¨ï¼‰
            test_count: æµ‹è¯•æ¨¡å¼ä¸‹åˆ†æçš„è‚¡ç¥¨æ•°é‡
        """
        if test_mode:
            logger.info(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªåˆ†æå‰ {test_count} åªè‚¡ç¥¨")
        else:
            logger.info(f"ğŸ” å¼€å§‹æ™ºèƒ½ç­›é€‰æ‰€æœ‰è‚¡ç¥¨ï¼ˆä¸¤é˜¶æ®µç­–ç•¥ï¼‰")
        
        # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç å’Œåç§°
        conn = sqlite3.connect(self.db_path)
        stocks = pd.read_sql_query("SELECT stock_code, stock_name FROM stocks", conn)
        conn.close()
        
        if test_mode:
            stocks = stocks.head(test_count)
            logger.info(f"æµ‹è¯•æ¨¡å¼ï¼šé™åˆ¶åˆ†æ {len(stocks)} åªè‚¡ç¥¨")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šåŸºæœ¬ç­›é€‰ + å†å²æ•°æ®åˆæ­¥è¯„åˆ†
        logger.info("ğŸ” ç¬¬ä¸€é˜¶æ®µï¼šåŸºæœ¬ç­›é€‰ + å†å²æ•°æ®åˆæ­¥è¯„åˆ†")
        preliminary_candidates = []
        skipped_count = 0
        skip_reasons = {}
        processed = 0
        
        for _, row in stocks.iterrows():
            stock_code = row['stock_code']
            stock_name = row['stock_name']
            
            # åŸºæœ¬ç­›é€‰
            should_skip, skip_reason = self._should_skip_stock(stock_code, stock_name)
            
            if should_skip:
                skipped_count += 1
                skip_reasons[skip_reason] = skip_reasons.get(skip_reason, 0) + 1
                logger.debug(f"è·³è¿‡è‚¡ç¥¨: {stock_code} {stock_name} - {skip_reason}")
                continue
            
            # å†å²æ•°æ®åˆæ­¥è¯„åˆ†ï¼ˆä¸ä½¿ç”¨å®æ—¶PEï¼‰
            try:
                preliminary_result = self.preliminary_screening(stock_code)
                
                if 'error' not in preliminary_result:
                    # æ·»åŠ æ½œåŠ›è¯„ä¼°
                    potential_score = self._assess_potential(stock_code, preliminary_result)
                    preliminary_result['potential_score'] = potential_score
                    preliminary_result['combined_score'] = preliminary_result['preliminary_score'] + potential_score
                    
                    preliminary_candidates.append(preliminary_result)
                    logger.debug(f"åˆæ­¥å€™é€‰: {stock_code} {preliminary_result['stock_name']} - "
                               f"åŸºç¡€: {preliminary_result['preliminary_score']:.1f}, "
                               f"æ½œåŠ›: {potential_score:.1f}, "
                               f"ç»¼åˆ: {preliminary_result['combined_score']:.1f}")
                
                processed += 1
                if processed % 100 == 0:
                    logger.info(f"å·²åˆç­› {processed}/{len(stocks)} åªè‚¡ç¥¨ï¼Œå‘ç° {len(preliminary_candidates)} åªå€™é€‰")
                    
            except Exception as e:
                logger.error(f"åˆæ­¥è¯„ä¼°è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                continue
        
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        preliminary_candidates.sort(key=lambda x: x['combined_score'], reverse=True)
        
        logger.info(f"ç¬¬ä¸€é˜¶æ®µå®Œæˆ:")
        logger.info(f"  - åŸå§‹è‚¡ç¥¨: {len(stocks)} åª")
        logger.info(f"  - è·³è¿‡è‚¡ç¥¨: {skipped_count} åª")
        logger.info(f"  - å€™é€‰è‚¡ç¥¨: {len(preliminary_candidates)} åª")
        if skip_reasons:
            logger.info(f"  - è·³è¿‡åŸå› ç»Ÿè®¡:")
            for reason, count in skip_reasons.items():
                logger.info(f"    â€¢ {reason}: {count} åª")
        
        if not preliminary_candidates:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å€™é€‰è‚¡ç¥¨")
            return []
        
        # ç¬¬äºŒé˜¶æ®µï¼šæ™ºèƒ½APIè°ƒç”¨ç­–ç•¥
        logger.info("ğŸ“¡ ç¬¬äºŒé˜¶æ®µï¼šæ™ºèƒ½å®æ—¶PEè¯„ä¼°")
        
        # åˆ†å±‚ç­–ç•¥ï¼šä¼˜å…ˆçº§è¶Šé«˜ï¼Œè¶Šéœ€è¦å‡†ç¡®çš„å®æ—¶PE
        high_priority = [c for c in preliminary_candidates if c['combined_score'] >= 65]  # é«˜æ½œåŠ›è‚¡ç¥¨
        medium_priority = [c for c in preliminary_candidates if 50 <= c['combined_score'] < 65]  # ä¸­ç­‰è‚¡ç¥¨
        low_priority = [c for c in preliminary_candidates if c['combined_score'] < 50]  # ä½åˆ†è‚¡ç¥¨
        
        logger.info(f"å€™é€‰è‚¡ç¥¨åˆ†å±‚:")
        logger.info(f"  - é«˜ä¼˜å…ˆçº§(â‰¥65åˆ†): {len(high_priority)} åª (å…¨éƒ¨ä½¿ç”¨å®æ—¶PE)")
        logger.info(f"  - ä¸­ä¼˜å…ˆçº§(50-64åˆ†): {len(medium_priority)} åª (é€‰æ‹©æ€§ä½¿ç”¨å®æ—¶PE)")
        logger.info(f"  - ä½ä¼˜å…ˆçº§(<50åˆ†): {len(low_priority)} åª (ä¸»è¦ä½¿ç”¨å†å²PE)")
        
        final_results = []
        api_calls = 0
        api_success = 0
        
        # å¤„ç†é«˜ä¼˜å…ˆçº§è‚¡ç¥¨ï¼ˆå…¨éƒ¨ä½¿ç”¨å®æ—¶PEï¼‰
        for candidate in high_priority:
            stock_code = candidate['stock_code']
            try:
                final_evaluation = self.comprehensive_evaluation(stock_code, use_realtime_pe=True)
                
                if final_evaluation.get('pe_api_used', False):
                    api_calls += 1
                    api_success += 1
                
                if 'error' not in final_evaluation:
                    final_results.append(final_evaluation)
                    logger.debug(f"âœ… é«˜ä¼˜å…ˆçº§: {stock_code} - è¯„åˆ†: {final_evaluation['total_score']:.1f}")
                
                # APIè°ƒç”¨é—´éš”
                if api_calls % 10 == 0:
                    time.sleep(0.5)
                    
            except Exception as e:
                logger.error(f"åˆ†æé«˜ä¼˜å…ˆçº§è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                continue
        
        # å¤„ç†ä¸­ä¼˜å…ˆçº§è‚¡ç¥¨ï¼ˆé€‰æ‹©æ€§ä½¿ç”¨å®æ—¶PEï¼‰
        medium_with_api = medium_priority[:min(len(medium_priority), 200)]  # æœ€å¤š200åªä½¿ç”¨API
        medium_without_api = medium_priority[len(medium_with_api):]
        
        logger.info(f"ä¸­ä¼˜å…ˆçº§å¤„ç†ç­–ç•¥: {len(medium_with_api)} åªä½¿ç”¨å®æ—¶PE, {len(medium_without_api)} åªä½¿ç”¨å†å²PE")
        
        # æœ‰APIçš„ä¸­ä¼˜å…ˆçº§è‚¡ç¥¨
        for candidate in medium_with_api:
            stock_code = candidate['stock_code']
            try:
                final_evaluation = self.comprehensive_evaluation(stock_code, use_realtime_pe=True)
                
                if final_evaluation.get('pe_api_used', False):
                    api_calls += 1
                    api_success += 1
                
                if 'error' not in final_evaluation:
                    final_results.append(final_evaluation)
                
                # APIè°ƒç”¨é—´éš”
                if api_calls % 20 == 0:
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"åˆ†æä¸­ä¼˜å…ˆçº§è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                continue
        
        # æ— APIçš„ä¸­ä¼˜å…ˆçº§è‚¡ç¥¨
        for candidate in medium_without_api:
            stock_code = candidate['stock_code']
            try:
                final_evaluation = self.comprehensive_evaluation(stock_code, use_realtime_pe=False)
                
                if 'error' not in final_evaluation:
                    final_results.append(final_evaluation)
                    
            except Exception as e:
                logger.error(f"åˆ†æä¸­ä¼˜å…ˆçº§è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                continue
        
        # å¤„ç†ä½ä¼˜å…ˆçº§è‚¡ç¥¨ï¼ˆä¸»è¦ä½¿ç”¨å†å²PEï¼Œå°‘é‡ä½¿ç”¨å®æ—¶PEï¼‰
        low_with_api = low_priority[:min(len(low_priority), 50)]  # æœ€å¤š50åªä½¿ç”¨API
        low_without_api = low_priority[len(low_with_api):]
        
        logger.info(f"ä½ä¼˜å…ˆçº§å¤„ç†ç­–ç•¥: {len(low_with_api)} åªä½¿ç”¨å®æ—¶PE, {len(low_without_api)} åªä½¿ç”¨å†å²PE")
        
        # æœ‰APIçš„ä½ä¼˜å…ˆçº§è‚¡ç¥¨
        for candidate in low_with_api:
            stock_code = candidate['stock_code']
            try:
                final_evaluation = self.comprehensive_evaluation(stock_code, use_realtime_pe=True)
                
                if final_evaluation.get('pe_api_used', False):
                    api_calls += 1
                    api_success += 1
                
                if 'error' not in final_evaluation:
                    final_results.append(final_evaluation)
                
                # APIè°ƒç”¨é—´éš”
                if api_calls % 30 == 0:
                    time.sleep(1.5)
                    
            except Exception as e:
                logger.error(f"åˆ†æä½ä¼˜å…ˆçº§è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                continue
        
        # æ— APIçš„ä½ä¼˜å…ˆçº§è‚¡ç¥¨
        for candidate in low_without_api:
            stock_code = candidate['stock_code']
            try:
                final_evaluation = self.comprehensive_evaluation(stock_code, use_realtime_pe=False)
                
                if 'error' not in final_evaluation:
                    final_results.append(final_evaluation)
                    
            except Exception as e:
                logger.error(f"åˆ†æä½ä¼˜å…ˆçº§è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                continue
        
        # æŒ‰æœ€ç»ˆå¾—åˆ†æ’åº
        final_results.sort(key=lambda x: x['total_score'], reverse=True)
        
        # å¯é€‰ï¼šDeepSeek AIåˆ†æï¼ˆåªå¯¹é«˜åˆ†è‚¡ç¥¨ï¼‰
        if self.deepseek_analyzer and final_results:
            top_for_ai = final_results[:min(50, len(final_results))]
            logger.info(f"ğŸ¤– DeepSeek AIåˆ†æï¼ˆåˆ†æå‰{len(top_for_ai)}åï¼‰")
            
            for i, result in enumerate(top_for_ai):
                if result['total_score'] < 60:  # åªå¯¹60åˆ†ä»¥ä¸Šçš„è‚¡ç¥¨è¿›è¡ŒAIåˆ†æ
                    break
                    
                stock_code = result['stock_code']
                try:
                    stock_data = self.get_stock_metrics(stock_code)
                    score_details = {
                        'total_score': result['total_score'],
                        'buffett': result['buffett_analysis'],
                        'munger': result['munger_analysis'],
                        'graham': result['graham_analysis']
                    }
                    
                    ai_analysis = self.deepseek_analyzer.analyze_stock(stock_code, stock_data, score_details)
                    
                    if ai_analysis:
                        result['ai_analysis'] = ai_analysis
                        logger.info(f"âœ… AIåˆ†æå®Œæˆ: {stock_code}")
                    else:
                        result['ai_analysis'] = "AIåˆ†ææš‚ä¸å¯ç”¨"
                        
                    if i < len(top_for_ai) - 1:
                        time.sleep(2)
                        
                except Exception as e:
                    logger.error(f"AIåˆ†æè‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                    result['ai_analysis'] = f"AIåˆ†æå‡ºé”™: {str(e)}"
        
        # ç»Ÿè®¡ä¿¡æ¯
        api_success_rate = (api_success / api_calls * 100) if api_calls > 0 else 0
        logger.info(f"ğŸ‰ æ™ºèƒ½ç­›é€‰å®Œæˆï¼")
        logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"   - åŸå§‹è‚¡ç¥¨æ•°: {len(stocks)}")
        logger.info(f"   - è·³è¿‡è‚¡ç¥¨æ•°: {skipped_count}")
        logger.info(f"   - å€™é€‰è‚¡ç¥¨æ•°: {len(preliminary_candidates)}")
        logger.info(f"   - æˆåŠŸåˆ†æ: {len(final_results)} åª")
        logger.info(f"   - APIè°ƒç”¨: {api_calls} æ¬¡ï¼ŒæˆåŠŸç‡: {api_success_rate:.1f}%")
        logger.info(f"   - APIè°ƒç”¨èŠ‚çœ: {len(preliminary_candidates) - api_calls} æ¬¡")
        
        if final_results:
            avg_final_score = np.mean([r['total_score'] for r in final_results])
            pe_used_count = sum(1 for r in final_results if r.get('pe_api_used', False))
            high_score_count = sum(1 for r in final_results if r['total_score'] >= 70)
            medium_score_count = sum(1 for r in final_results if 50 <= r['total_score'] < 70)
            low_score_count = sum(1 for r in final_results if r['total_score'] < 50)
            
            logger.info(f"   - å¹³å‡å¾—åˆ†: {avg_final_score:.1f}")
            logger.info(f"   - ä½¿ç”¨å®æ—¶PE: {pe_used_count} åª")
            logger.info(f"   - é«˜åˆ†è‚¡ç¥¨(â‰¥70): {high_score_count} åª")
            logger.info(f"   - ä¸­åˆ†è‚¡ç¥¨(50-69): {medium_score_count} åª")
            logger.info(f"   - ä½åˆ†è‚¡ç¥¨(<50): {low_score_count} åª")
        
        return final_results
    
    def generate_report(self, value_stocks: List[Dict], output_file: str = None) -> str:
        """ç”ŸæˆæŠ•èµ„æŠ¥å‘Šï¼ˆæ”¯æŒmarkdownå’ŒExcelæ ¼å¼ï¼‰"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if not output_file:
            base_name = f"value_investment_report_{timestamp}"
            md_file = f"{base_name}.md"
            excel_file = f"{base_name}.xlsx"
        else:
            # å¦‚æœç”¨æˆ·æŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼Œç”Ÿæˆå¯¹åº”çš„Excelæ–‡ä»¶å
            if output_file.endswith('.md'):
                md_file = output_file
                excel_file = output_file.replace('.md', '.xlsx')
            else:
                md_file = f"{output_file}.md"
                excel_file = f"{output_file}.xlsx"
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self._generate_markdown_report(value_stocks, md_file)
        
        # ç”ŸæˆExcelæŠ¥å‘Š
        self._generate_excel_report(value_stocks, excel_file)
        
        logger.info(f"æŠ•èµ„æŠ¥å‘Šå·²ä¿å­˜: {md_file} å’Œ {excel_file}")
        return md_file
    
    def _generate_markdown_report(self, value_stocks: List[Dict], output_file: str):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        report_lines = [
            "# ğŸ¯ ä»·å€¼æŠ•èµ„åˆ†ææŠ¥å‘Š",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**ç­›é€‰æ•°é‡**: {len(value_stocks)} åªè‚¡ç¥¨",
            "",
            "## ğŸ“Š æŠ•èµ„å¤§å¸ˆè¯„åˆ†ä½“ç³»",
            "",
            "### ğŸ† å·´è²ç‰¹æ ‡å‡† (æƒé‡40%)",
            "- æŒç»­é«˜ROE (>15%)",
            "- ä½å€ºåŠ¡æ¯”ç‡ (<30%)",
            "- ç¨³å®šç›ˆåˆ©èƒ½åŠ›",
            "- å¼ºåŠ²ç°é‡‘æµ",
            "",
            "### ğŸ§  æŸ¥ç†èŠ’æ ¼æ ‡å‡† (æƒé‡30%)",
            "- ä¼˜è´¨è¡Œä¸šé€‰æ‹©",
            "- é«˜ç»è¥æ•ˆç‡",
            "- å¼ºå®šä»·æƒï¼ˆé«˜æ¯›åˆ©ç‡ï¼‰",
            "- åˆç†ä¼°å€¼",
            "",
            "### ğŸ“š æ ¼é›·å„å§†æ ‡å‡† (æƒé‡30%)",
            "- ä½PEä¼°å€¼ (<12x)",
            "- ä½PBæ¯”ç‡ (<2x)",
            "- å®‰å…¨è¾¹é™…å……è¶³",
            "- ç¨³å®šè‚¡æ¯å›æŠ¥",
            "",
            "## ğŸŒŸ ç²¾é€‰ä»·å€¼è‚¡ç¥¨",
            ""
        ]
        
        for i, stock in enumerate(value_stocks, 1):
            report_lines.extend([
                f"### {i}. {stock['stock_name']} ({stock['stock_code']})",
                f"**ç»¼åˆè¯„åˆ†**: {stock['total_score']}/100 - {stock['grade']}",
                f"**æ‰€å±è¡Œä¸š**: {stock['industry']}",
                "",
                "#### ğŸ† å·´è²ç‰¹åˆ†æ",
                f"**å¾—åˆ†**: {stock['buffett_analysis']['score']}/100",
                *[f"- {detail}" for detail in stock['buffett_analysis']['details']],
                "",
                "#### ğŸ§  èŠ’æ ¼åˆ†æ", 
                f"**å¾—åˆ†**: {stock['munger_analysis']['score']}/100",
                *[f"- {detail}" for detail in stock['munger_analysis']['details']],
                "",
                "#### ğŸ“š æ ¼é›·å„å§†åˆ†æ",
                f"**å¾—åˆ†**: {stock['graham_analysis']['score']}/100", 
                *[f"- {detail}" for detail in stock['graham_analysis']['details']],
                ""
            ])
            
            # æ·»åŠ AIåˆ†æéƒ¨åˆ†
            if 'ai_analysis' in stock and stock['ai_analysis']:
                if 'AIåˆ†ææš‚ä¸å¯ç”¨' in stock['ai_analysis'] or 'AIåˆ†æå‡ºé”™' in stock['ai_analysis']:
                    report_lines.extend([
                        "#### ğŸ¤– AIæ·±åº¦åˆ†æ",
                        f"**çŠ¶æ€**: {stock['ai_analysis']}",
                        ""
                    ])
                else:
                    report_lines.extend([
                        "#### ğŸ¤– AIæ·±åº¦åˆ†æ",
                        "",
                        stock['ai_analysis'],
                        ""
                    ])
            
            report_lines.extend([
                "---",
                ""
            ])
        
        report_lines.extend([
            "",
            "## âš ï¸ é‡è¦å£°æ˜",
            "",
            "1. æœ¬æŠ¥å‘Šä»…åŸºäºå†å²è´¢åŠ¡æ•°æ®åˆ†æï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®",
            "2. æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…",
            "3. å»ºè®®ç»“åˆå®æ—¶å¸‚åœºä¿¡æ¯å’Œä¸ªäººé£é™©æ‰¿å—èƒ½åŠ›åšå‡ºæŠ•èµ„å†³ç­–",
            "4. ä»·å€¼æŠ•èµ„éœ€è¦é•¿æœŸæŒæœ‰ï¼Œé¿å…çŸ­æœŸæŠ•æœº",
            "",
            f"---",
            f"*æŠ¥å‘Šç”±ä»·å€¼æŠ•èµ„Agentç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
        
        report_content = '\n'.join(report_lines)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
    
    def _generate_excel_report(self, value_stocks: List[Dict], output_file: str):
        """ç”ŸæˆExcelæ ¼å¼æŠ¥å‘Š"""
        try:
            # åˆ›å»ºå·¥ä½œç°¿
            from openpyxl import Workbook
            from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            wb = Workbook()
            
            # åˆ é™¤é»˜è®¤å·¥ä½œè¡¨
            wb.remove(wb.active)
            
            # 1. åˆ›å»ºæ¦‚è§ˆè¡¨
            self._create_overview_sheet(wb, value_stocks)
            
            # 2. åˆ›å»ºè¯¦ç»†è¯„åˆ†è¡¨
            self._create_detailed_scores_sheet(wb, value_stocks)
            
            # 3. åˆ›å»ºè´¢åŠ¡æŒ‡æ ‡è¡¨
            self._create_financial_metrics_sheet(wb, value_stocks)
            
            # ä¿å­˜æ–‡ä»¶
            wb.save(output_file)
            logger.info(f"ExcelæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            
        except ImportError:
            logger.warning("openpyxlæœªå®‰è£…ï¼Œæ— æ³•ç”ŸæˆExcelæŠ¥å‘Šã€‚è¯·è¿è¡Œ: pip install openpyxl")
        except Exception as e:
            logger.error(f"ç”ŸæˆExcelæŠ¥å‘Šå¤±è´¥: {e}")
    
    def _create_overview_sheet(self, wb, value_stocks):
        """åˆ›å»ºæ¦‚è§ˆå·¥ä½œè¡¨"""
        from openpyxl.styles import Font, Alignment, PatternFill
        
        ws = wb.create_sheet("ğŸ“Š è‚¡ç¥¨æ¦‚è§ˆ", 0)
        
        # è®¾ç½®æ ‡é¢˜ - é‡æ–°è®¾è®¡ä¸ºæ›´å®ç”¨çš„ç»“æ„
        headers = [
            "æ’å", "è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "æ‰€å±è¡Œä¸š", 
            "ç»¼åˆè¯„åˆ†", "æŠ•èµ„ç­‰çº§",
            "ROE(%)", "ROEå¹´ä»½", "å€ºåŠ¡æ¯”ç‡(%)", "å€ºåŠ¡å¹´ä»½", 
            "æµåŠ¨æ¯”ç‡", "æµåŠ¨å¹´ä»½", "æ¯›åˆ©ç‡(%)", "æ¯›åˆ©å¹´ä»½", 
            "å‡€åˆ©ç‡(%)", "å‡€åˆ©å¹´ä»½", "å¸‚å‡€ç‡", "å¸‚å‡€å¹´ä»½",
            "å†å²PE(å¹´æŠ¥)", "PEå¹´ä»½", "å®æ—¶PE(å½“å‰)",
            "å·´è²ç‰¹å¾—åˆ†", "èŠ’æ ¼å¾—åˆ†", "æ ¼é›·å„å§†å¾—åˆ†", 
            "åˆ†ææ—¶é—´"
        ]
        
        # å†™å…¥æ ‡é¢˜è¡Œ
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = Font(bold=True, color="FFFFFF")
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.alignment = Alignment(horizontal="center", vertical="center")
        
        # å†™å…¥æ•°æ®è¡Œ
        for row, stock in enumerate(value_stocks, 2):
            # è·å–è¯¦ç»†è´¢åŠ¡æ•°æ®
            stock_data = self.get_stock_metrics(stock['stock_code'])
            metrics = stock_data.get('metrics', {}) if stock_data else {}
            
            # åŸºæœ¬ä¿¡æ¯
            ws.cell(row=row, column=1, value=row-1)  # æ’å
            ws.cell(row=row, column=2, value=stock['stock_code'])
            ws.cell(row=row, column=3, value=stock['stock_name'])
            ws.cell(row=row, column=4, value=stock['industry'])
            ws.cell(row=row, column=5, value=round(stock['total_score'], 1))
            ws.cell(row=row, column=6, value=stock['grade'])
            
            # è´¢åŠ¡æŒ‡æ ‡ï¼ˆå–æœ€æ–°å¹´ä»½æ•°æ®ï¼‰
            col_idx = 7
            
            # ROE
            roe_data = metrics.get('roe', {})
            if roe_data:
                latest_year = max(roe_data.keys())
                roe_value = roe_data[latest_year]
                ws.cell(row=row, column=col_idx, value=round(roe_value, 2) if pd.notna(roe_value) else None)
                ws.cell(row=row, column=col_idx+1, value=latest_year)
            col_idx += 2
            
            # å€ºåŠ¡æ¯”ç‡
            debt_data = metrics.get('debt_ratio', {})
            if debt_data:
                latest_year = max(debt_data.keys())
                debt_value = debt_data[latest_year]
                ws.cell(row=row, column=col_idx, value=round(debt_value, 2) if pd.notna(debt_value) else None)
                ws.cell(row=row, column=col_idx+1, value=latest_year)
            col_idx += 2
            
            # æµåŠ¨æ¯”ç‡
            current_data = metrics.get('current_ratio', {})
            if current_data:
                latest_year = max(current_data.keys())
                current_value = current_data[latest_year]
                ws.cell(row=row, column=col_idx, value=round(current_value, 2) if pd.notna(current_value) else None)
                ws.cell(row=row, column=col_idx+1, value=latest_year)
            col_idx += 2
            
            # æ¯›åˆ©ç‡
            gross_data = metrics.get('gross_margin', {})
            if gross_data:
                latest_year = max(gross_data.keys())
                gross_value = gross_data[latest_year]
                ws.cell(row=row, column=col_idx, value=round(gross_value, 2) if pd.notna(gross_value) else None)
                ws.cell(row=row, column=col_idx+1, value=latest_year)
            col_idx += 2
            
            # å‡€åˆ©ç‡
            net_data = metrics.get('net_margin', {})
            if net_data:
                latest_year = max(net_data.keys())
                net_value = net_data[latest_year]
                ws.cell(row=row, column=col_idx, value=round(net_value, 2) if pd.notna(net_value) else None)
                ws.cell(row=row, column=col_idx+1, value=latest_year)
            col_idx += 2
            
            # å¸‚å‡€ç‡
            pb_data = metrics.get('pb', {})
            if pb_data:
                latest_year = max(pb_data.keys())
                pb_value = pb_data[latest_year]
                ws.cell(row=row, column=col_idx, value=round(pb_value, 2) if pd.notna(pb_value) else None)
                ws.cell(row=row, column=col_idx+1, value=latest_year)
            col_idx += 2
            
            # å†å²PE(å¹´æŠ¥)
            pe_data = metrics.get('pe', {})
            if pe_data:
                latest_year = max(pe_data.keys())
                pe_value = pe_data[latest_year]
                ws.cell(row=row, column=col_idx, value=round(pe_value, 2) if pd.notna(pe_value) else None)
                ws.cell(row=row, column=col_idx+1, value=latest_year)
            col_idx += 2
            
            # å®æ—¶PE(å½“å‰)
            realtime_pe = stock.get('realtime_pe')
            ws.cell(row=row, column=col_idx, value=round(realtime_pe, 2) if realtime_pe else None)
            col_idx += 1
            
            # è¯„åˆ†ä¿¡æ¯
            ws.cell(row=row, column=col_idx, value=stock['buffett_analysis']['score'])
            ws.cell(row=row, column=col_idx+1, value=stock['munger_analysis']['score'])
            ws.cell(row=row, column=col_idx+2, value=stock['graham_analysis']['score'])
            ws.cell(row=row, column=col_idx+3, value=stock.get('evaluation_date', ''))
            
            # æ ¹æ®è¯„åˆ†è®¾ç½®è¡Œé¢œè‰²
            if stock['total_score'] >= 80:
                fill_color = "E8F5E8"  # æµ…ç»¿è‰²
            elif stock['total_score'] >= 70:
                fill_color = "FFF2CC"  # æµ…é»„è‰²
            else:
                fill_color = "FFFFFF"  # ç™½è‰²
                
            for col in range(1, len(headers) + 1):
                ws.cell(row=row, column=col).fill = PatternFill(start_color=fill_color, end_color=fill_color, fill_type="solid")
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 20)
            ws.column_dimensions[column_letter].width = adjusted_width
    
    def _create_detailed_scores_sheet(self, wb, value_stocks):
        """åˆ›å»ºè¯¦ç»†è¯„åˆ†å·¥ä½œè¡¨"""
        from openpyxl.styles import Font, Alignment, PatternFill
        
        ws = wb.create_sheet("ğŸ“ˆ è¯¦ç»†è¯„åˆ†", 1)
        
        # è®¾ç½®æ ‡é¢˜
        headers = ["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "è¯„åˆ†é¡¹ç›®", "å¾—åˆ†è¯¦æƒ…", "è¯„åˆ†è¯´æ˜"]
        
        # å†™å…¥æ ‡é¢˜è¡Œ
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = Font(bold=True, color="FFFFFF")
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.alignment = Alignment(horizontal="center", vertical="center")
        
        current_row = 2
        for stock in value_stocks:
            stock_code = stock['stock_code']
            stock_name = stock['stock_name']
            
            # å·´è²ç‰¹è¯„åˆ†è¯¦æƒ…
            for detail in stock['buffett_analysis']['details']:
                ws.cell(row=current_row, column=1, value=stock_code)
                ws.cell(row=current_row, column=2, value=stock_name)
                ws.cell(row=current_row, column=3, value="ğŸ† å·´è²ç‰¹åˆ†æ")
                ws.cell(row=current_row, column=4, value=detail)
                ws.cell(row=current_row, column=5, value=stock['buffett_analysis']['methodology'])
                current_row += 1
            
            # èŠ’æ ¼è¯„åˆ†è¯¦æƒ…
            for detail in stock['munger_analysis']['details']:
                ws.cell(row=current_row, column=1, value=stock_code)
                ws.cell(row=current_row, column=2, value=stock_name)
                ws.cell(row=current_row, column=3, value="ğŸ§  èŠ’æ ¼åˆ†æ")
                ws.cell(row=current_row, column=4, value=detail)
                ws.cell(row=current_row, column=5, value=stock['munger_analysis']['methodology'])
                current_row += 1
            
            # æ ¼é›·å„å§†è¯„åˆ†è¯¦æƒ…
            for detail in stock['graham_analysis']['details']:
                ws.cell(row=current_row, column=1, value=stock_code)
                ws.cell(row=current_row, column=2, value=stock_name)
                ws.cell(row=current_row, column=3, value="ğŸ“š æ ¼é›·å„å§†åˆ†æ")
                ws.cell(row=current_row, column=4, value=detail)
                ws.cell(row=current_row, column=5, value=stock['graham_analysis']['methodology'])
                current_row += 1
            
            # æ·»åŠ åˆ†éš”è¡Œ
            current_row += 1
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws.column_dimensions[column_letter].width = adjusted_width
    
    def _create_financial_metrics_sheet(self, wb, value_stocks):
        """åˆ›å»ºè´¢åŠ¡æŒ‡æ ‡å·¥ä½œè¡¨ - å¤šå¹´æ•°æ®å¯¹æ¯”"""
        from openpyxl.styles import Font, Alignment, PatternFill
        
        ws = wb.create_sheet("ğŸ’° å¤šå¹´è´¢åŠ¡æŒ‡æ ‡", 2)
        
        if not value_stocks:
            return
        
        # æ„å»ºå¤šå¹´æ•°æ®è¡¨æ ¼
        years = [2020, 2021, 2022, 2023, 2024]
        metrics_names = {
            'roe': 'ROE(%)',
            'debt_ratio': 'å€ºåŠ¡æ¯”ç‡(%)',
            'current_ratio': 'æµåŠ¨æ¯”ç‡',
            'gross_margin': 'æ¯›åˆ©ç‡(%)',
            'net_margin': 'å‡€åˆ©ç‡(%)',
            'pb': 'å¸‚å‡€ç‡',
            'pe': 'PE',
            'asset_turnover': 'èµ„äº§å‘¨è½¬ç‡',
            'dividend': 'è‚¡æ¯ç‡(%)'
        }
        
        # è®¾ç½®æ ‡é¢˜è¡Œ
        headers = ["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "æŒ‡æ ‡"]
        for year in years:
            headers.append(f"{year}å¹´")
        headers.extend(["å¹³å‡å€¼", "è¶‹åŠ¿", "è¯„ä»·"])
        
        # å†™å…¥æ ‡é¢˜è¡Œ
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = Font(bold=True, color="FFFFFF")
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.alignment = Alignment(horizontal="center", vertical="center")
        
        current_row = 2
        
        for stock in value_stocks:
            stock_code = stock['stock_code']
            stock_name = stock['stock_name']
            
            # è·å–è´¢åŠ¡æ•°æ®
            stock_data = self.get_stock_metrics(stock_code)
            metrics = stock_data.get('metrics', {}) if stock_data else {}
            
            for metric_key, metric_name in metrics_names.items():
                if metric_key in metrics:
                    metric_data = metrics[metric_key]
                    
                    # åŸºæœ¬ä¿¡æ¯
                    ws.cell(row=current_row, column=1, value=stock_code)
                    ws.cell(row=current_row, column=2, value=stock_name)
                    ws.cell(row=current_row, column=3, value=metric_name)
                    
                    # å„å¹´æ•°æ®
                    values = []
                    col_idx = 4
                    for year in years:
                        value = metric_data.get(year)
                        if value is not None and pd.notna(value):
                            ws.cell(row=current_row, column=col_idx, value=round(value, 2))
                            values.append(value)
                        else:
                            ws.cell(row=current_row, column=col_idx, value=None)
                        col_idx += 1
                    
                    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                    if values:
                        avg_value = np.mean(values)
                        trend = self._calculate_trend(values)
                        
                        # å¹³å‡å€¼
                        ws.cell(row=current_row, column=col_idx, value=round(avg_value, 2))
                        col_idx += 1
                        
                        # è¶‹åŠ¿
                        if trend > 0.1:
                            trend_str = "ä¸Šå‡ğŸ“ˆ"
                        elif trend < -0.1:
                            trend_str = "ä¸‹é™ğŸ“‰"
                        else:
                            trend_str = "ç¨³å®šâ¡ï¸"
                        ws.cell(row=current_row, column=col_idx, value=trend_str)
                        col_idx += 1
                        
                        # è¯„ä»·
                        evaluation = self._evaluate_metric(metric_key, avg_value, trend)
                        ws.cell(row=current_row, column=col_idx, value=evaluation)
                    
                    current_row += 1
            
            # æ·»åŠ åˆ†éš”è¡Œ
            current_row += 1
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 15)
            ws.column_dimensions[column_letter].width = adjusted_width
    
    def _evaluate_metric(self, metric_key: str, avg_value: float, trend: float) -> str:
        """è¯„ä»·è´¢åŠ¡æŒ‡æ ‡"""
        evaluations = {
            'roe': {
                'excellent': 20,
                'good': 15,
                'fair': 10,
                'unit': '%'
            },
            'debt_ratio': {
                'excellent': 30,  # ä½äº30%ä¸ºä¼˜ç§€
                'good': 50,
                'fair': 70,
                'unit': '%',
                'reverse': True  # è¶Šä½è¶Šå¥½
            },
            'current_ratio': {
                'excellent': 2.0,
                'good': 1.5,
                'fair': 1.0,
                'unit': ''
            },
            'gross_margin': {
                'excellent': 30,
                'good': 20,
                'fair': 10,
                'unit': '%'
            },
            'net_margin': {
                'excellent': 10,
                'good': 5,
                'fair': 2,
                'unit': '%'
            },
            'pb': {
                'excellent': 2.0,
                'good': 3.0,
                'fair': 5.0,
                'unit': '',
                'reverse': True  # è¶Šä½è¶Šå¥½
            },
            'pe': {
                'excellent': 15,
                'good': 25,
                'fair': 40,
                'unit': '',
                'reverse': True  # è¶Šä½è¶Šå¥½
            }
        }
        
        if metric_key not in evaluations:
            return "æ— è¯„ä»·æ ‡å‡†"
        
        standards = evaluations[metric_key]
        is_reverse = standards.get('reverse', False)
        
        if is_reverse:
            # è¶Šä½è¶Šå¥½çš„æŒ‡æ ‡
            if avg_value <= standards['excellent']:
                quality = "ä¼˜ç§€âœ¨"
            elif avg_value <= standards['good']:
                quality = "è‰¯å¥½âœ…"
            elif avg_value <= standards['fair']:
                quality = "ä¸€èˆ¬ğŸ“Š"
            else:
                quality = "è¾ƒå·®âš ï¸"
        else:
            # è¶Šé«˜è¶Šå¥½çš„æŒ‡æ ‡
            if avg_value >= standards['excellent']:
                quality = "ä¼˜ç§€âœ¨"
            elif avg_value >= standards['good']:
                quality = "è‰¯å¥½âœ…"
            elif avg_value >= standards['fair']:
                quality = "ä¸€èˆ¬ğŸ“Š"
            else:
                quality = "è¾ƒå·®âš ï¸"
        
        # æ·»åŠ è¶‹åŠ¿ä¿¡æ¯
        if trend > 0.1:
            trend_desc = " å‘å¥½"
        elif trend < -0.1:
            trend_desc = " èµ°å¼±"
        else:
            trend_desc = ""
        
        return f"{quality}{trend_desc}"
    
    def _calculate_trend(self, values: List[float]) -> float:
        """è®¡ç®—è¶‹åŠ¿ï¼ˆæ­£å€¼è¡¨ç¤ºä¸Šå‡ï¼Œè´Ÿå€¼è¡¨ç¤ºä¸‹é™ï¼‰"""
        if len(values) < 2:
            return 0
        
        x = np.arange(len(values))
        coeffs = np.polyfit(x, values, 1)
        return coeffs[0]  # è¿”å›æ–œç‡
    
    def _calculate_growth_rate(self, values: List[float]) -> float:
        """è®¡ç®—å¢é•¿ç‡"""
        if len(values) < 2:
            return 0
        
        start_value = values[0]
        end_value = values[-1]
        years = len(values) - 1
        
        if start_value <= 0:
            return 0
        
        return (end_value / start_value) ** (1/years) - 1
    
    def analyze_single_stock(self, stock_code: str) -> Dict:
        """åˆ†æå•ä¸ªè‚¡ç¥¨"""
        try:
            return self.comprehensive_evaluation(stock_code, use_realtime_pe=True)
        except Exception as e:
            logger.error(f"åˆ†æå•ä¸ªè‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            return {'error': str(e)}
    
    def export_to_excel(self, results: List[Dict], filename: str = None) -> str:
        """å¯¼å‡ºç»“æœåˆ°Excelæ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"value_stocks_analysis_{timestamp}.xlsx"
        
        try:
            self._generate_excel_report(results, filename)
            return filename
        except Exception as e:
            logger.error(f"å¯¼å‡ºExcelå¤±è´¥: {e}")
            return ""
    
    def generate_analysis_report(self, results: List[Dict], filename: str = None) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not filename:
            filename = "ä»·å€¼æŠ•èµ„åˆ†ææŠ¥å‘Š.md"
        
        try:
            self._generate_markdown_report(results, filename)
            return filename
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='ä»·å€¼æŠ•èµ„åˆ†æå·¥å…·')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼ˆåªåˆ†æå°‘é‡è‚¡ç¥¨ï¼‰')
    parser.add_argument('--test-count', type=int, default=100, help='æµ‹è¯•æ¨¡å¼ä¸‹åˆ†æçš„è‚¡ç¥¨æ•°é‡ï¼ˆé»˜è®¤100ï¼‰')
    parser.add_argument('--output-excel', action='store_true', help='è¾“å‡ºExcelæ–‡ä»¶')
    parser.add_argument('--stock', type=str, help='åˆ†æå•ä¸ªè‚¡ç¥¨ï¼ˆè‚¡ç¥¨ä»£ç ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–åˆ†æå™¨
        agent = ValueInvestmentAgent()
        
        if args.stock:
            # å•ä¸ªè‚¡ç¥¨åˆ†æ
            logger.info(f"å¼€å§‹åˆ†æå•ä¸ªè‚¡ç¥¨: {args.stock}")
            result = agent.analyze_single_stock(args.stock)
            
            if result and 'error' not in result:
                print("\n" + "="*80)
                print(f"è‚¡ç¥¨åˆ†æç»“æœ: {result['stock_name']} ({result['stock_code']})")
                print("="*80)
                print(f"ç»¼åˆè¯„åˆ†: {result['total_score']:.1f}")
                print(f"è¡Œä¸š: {result['industry']}")
                if result.get('realtime_pe'):
                    print(f"å®æ—¶PE: {result['realtime_pe']:.2f}")
                print("="*80)
            else:
                print(f"åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        else:
            # æ‰¹é‡è‚¡ç¥¨ç­›é€‰
            if args.test:
                logger.info(f"ğŸ§ª å¯åŠ¨æµ‹è¯•æ¨¡å¼ï¼Œåˆ†æå‰{args.test_count}åªè‚¡ç¥¨")
            else:
                logger.info("ğŸš€ å¯åŠ¨æ™ºèƒ½ä»·å€¼æŠ•èµ„åˆ†æï¼ˆä¸¤é˜¶æ®µç­–ç•¥ï¼‰")
            
            # æ‰§è¡Œç­›é€‰
            results = agent.screen_value_stocks(
                test_mode=args.test, 
                test_count=args.test_count
            )
            
            if results:
                logger.info(f"âœ… æˆåŠŸåˆ†æ {len(results)} åªè‚¡ç¥¨")
                
                # æ˜¾ç¤ºåˆ†ææ‘˜è¦
                print("\n" + "="*100)
                print("ğŸ“Š ä»·å€¼æŠ•èµ„åˆ†ææ‘˜è¦")
                print("="*100)
                
                # ç»Ÿè®¡ä¿¡æ¯
                high_score = [r for r in results if r['total_score'] >= 70]
                medium_score = [r for r in results if 50 <= r['total_score'] < 70]
                
                print(f"æ€»åˆ†æè‚¡ç¥¨: {len(results)} åª")
                print(f"é«˜åˆ†è‚¡ç¥¨(â‰¥70åˆ†): {len(high_score)} åª")
                print(f"ä¸­ç­‰è‚¡ç¥¨(50-69åˆ†): {len(medium_score)} åª")
                print(f"APIè°ƒç”¨ç»Ÿè®¡: {sum(1 for r in results if r.get('pe_api_used', False))} æ¬¡")
                
                # æ˜¾ç¤ºå‰10å
                print(f"\nğŸ† å‰10åä¼˜è´¨è‚¡ç¥¨:")
                print("-"*100)
                print(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<10} {'è‚¡ç¥¨åç§°':<20} {'ç»¼åˆè¯„åˆ†':<8} {'å®æ—¶PE':<8} {'è¡Œä¸š':<20}")
                print("-"*100)
                
                for i, stock in enumerate(results[:10], 1):
                    realtime_pe = stock.get('realtime_pe', stock.get('pe_ratio', 'N/A'))
                    pe_str = f"{realtime_pe:.1f}" if isinstance(realtime_pe, (int, float)) else str(realtime_pe)
                    print(f"{i:<4} {stock['stock_code']:<10} {stock['stock_name'][:18]:<20} "
                          f"{stock['total_score']:<8.1f} {pe_str:<8} {stock['industry'][:18]:<20}")
                
                # è¾“å‡ºExcel
                if args.output_excel or not args.test:  # éæµ‹è¯•æ¨¡å¼é»˜è®¤è¾“å‡ºExcel
                    logger.info("ğŸ“„ å¼€å§‹ç”ŸæˆExcelæŠ¥å‘Š...")
                    agent.export_to_excel(results)
                    logger.info("âœ… ExcelæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
                
                # è¾“å‡ºMarkdown
                agent.generate_analysis_report(results)
                
                print("\n" + "="*100)
                print("ğŸ“ˆ åˆ†æå®Œæˆï¼")
                if args.output_excel or not args.test:
                    print("ğŸ“Š ExcelæŠ¥å‘Š: value_stocks_analysis.xlsx")
                print("ğŸ“ MarkdownæŠ¥å‘Š: ä»·å€¼æŠ•èµ„åˆ†ææŠ¥å‘Š.md")
                print("="*100)
                
            else:
                logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
                
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åºè¿è¡Œ")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 