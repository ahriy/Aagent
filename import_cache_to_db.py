#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»ç¼“å­˜æ–‡ä»¶é‡æ–°å¯¼å…¥æ•°æ®åˆ°SQLiteæ•°æ®åº“
æ¸…ç©ºç°æœ‰æ•°æ®å¹¶é‡æ–°å¯¼å…¥
"""

import json
import os
import sqlite3
import pandas as pd
from loguru import logger
from datetime import datetime

def setup_logger():
    """è®¾ç½®æ—¥å¿—"""
    logger.add(
        "logs/cache_reimport_{time}.log",
        rotation="10 MB",
        encoding="utf-8"
    )

def clear_database(db_path='stock_analysis.db'):
    """æ¸…ç©ºæ•°æ®åº“ç°æœ‰æ•°æ®"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    logger.info("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®åº“ç°æœ‰æ•°æ®...")
    
    # åˆ é™¤æ‰€æœ‰æ•°æ®
    cursor.execute('DELETE FROM financial_metrics')
    cursor.execute('DELETE FROM stocks')
    
    # é‡ç½®è‡ªå¢ID
    cursor.execute('DELETE FROM sqlite_sequence WHERE name="financial_metrics"')
    
    conn.commit()
    conn.close()
    
    logger.info("âœ… æ•°æ®åº“å·²æ¸…ç©º")

def process_cache_data(cache_data):
    """å¤„ç†ç¼“å­˜æ•°æ®ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
    results = []
    
    for stock_code, stock_info in cache_data.items():
        if not stock_info or 'data' not in stock_info:
            continue
            
        name = stock_info.get('name', '')
        industry = stock_info.get('industry', '')
        data = stock_info['data']
        
        # åŸºç¡€ä¿¡æ¯
        row = {
            'stock_code': stock_code,
            'stock_name': name,
            'industry': industry
        }
        
        # å¤„ç†è´¢åŠ¡æŒ‡æ ‡
        if 'financial_indicators' in data:
            for indicator in data['financial_indicators']:
                year = indicator.get('end_date', '')[:4]
                if year and year.isdigit():
                    year = int(year)
                    
                    # ROE
                    if indicator.get('roe') is not None:
                        row[f'roe_{year}'] = indicator['roe']
                    
                    # æ¯›åˆ©ç‡
                    if indicator.get('grossprofit_margin') is not None:
                        row[f'gross_margin_{year}'] = indicator['grossprofit_margin']
                    
                    # å‡€åˆ©ç‡
                    if indicator.get('netprofit_margin') is not None:
                        row[f'net_margin_{year}'] = indicator['netprofit_margin']
                    
                    # èµ„äº§è´Ÿå€ºç‡
                    if indicator.get('debt_to_assets') is not None:
                        row[f'debt_ratio_{year}'] = indicator['debt_to_assets'] / 100
                    
                    # æµåŠ¨æ¯”ç‡
                    if indicator.get('current_ratio') is not None:
                        row[f'current_ratio_{year}'] = indicator['current_ratio']
                    
                    # èµ„äº§å‘¨è½¬ç‡
                    if indicator.get('assets_turn') is not None:
                        row[f'asset_turnover_{year}'] = indicator['assets_turn']
        
        # å¤„ç†PEæ•°æ®
        if 'pe' in data:
            for pe_record in data['pe']:
                year = pe_record.get('trade_date', '')[:4]
                if year and year.isdigit() and pe_record.get('pe') is not None:
                    row[f'pe_{year}'] = pe_record['pe']
        
        # å¤„ç†PBæ•°æ®
        if 'pb' in data:
            for pb_record in data['pb']:
                year = pb_record.get('trade_date', '')[:4]
                if year and year.isdigit() and pb_record.get('pb') is not None:
                    row[f'pb_{year}'] = pb_record['pb']
        
        # å¤„ç†è‚¡æ¯ç‡æ•°æ®
        if 'dividend' in data:
            for div_record in data['dividend']:
                year = div_record.get('trade_date', '')[:4]
                if year and year.isdigit() and div_record.get('dv_ratio') is not None:
                    row[f'dividend_{year}'] = div_record['dv_ratio']
        
        # å¤„ç†æ€»èµ„äº§æ•°æ®
        if 'balance_sheet' in data:
            for bs_record in data['balance_sheet']:
                year = bs_record.get('end_date', '')[:4]
                if year and year.isdigit() and bs_record.get('total_assets') is not None:
                    row[f'total_assets_{year}'] = bs_record['total_assets']
        
        results.append(row)
    
    return results

def save_to_sqlite(data, db_path='stock_analysis.db'):
    """ä¿å­˜æ•°æ®åˆ°SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect(db_path)
    
    for _, row in data.iterrows():
        # æ’å…¥è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        conn.execute('''
            INSERT OR REPLACE INTO stocks (stock_code, stock_name, industry)
            VALUES (?, ?, ?)
        ''', (row['stock_code'], row['stock_name'], row['industry']))
        
        # æ’å…¥è´¢åŠ¡æŒ‡æ ‡æ•°æ®
        for col in row.index:
            if col in ['stock_code', 'stock_name', 'industry']:
                continue
                
            # è§£ææŒ‡æ ‡åç§°å’Œå¹´ä»½
            if '_' in col:
                parts = col.split('_')
                if len(parts) >= 2:
                    metric_name = '_'.join(parts[:-1])
                    year = parts[-1]
                    
                    if pd.notna(row[col]) and year.isdigit():
                        conn.execute('''
                            INSERT OR REPLACE INTO financial_metrics 
                            (stock_code, year, metric_name, metric_value)
                            VALUES (?, ?, ?, ?)
                        ''', (row['stock_code'], int(year), metric_name, float(row[col])))
    
    conn.commit()
    conn.close()

def create_sqlite_database(db_path='stock_analysis.db'):
    """åˆ›å»ºSQLiteæ•°æ®åº“å’Œè¡¨ç»“æ„"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # åˆ›å»ºè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS stocks (
            stock_code TEXT PRIMARY KEY,
            stock_name TEXT,
            industry TEXT,
            list_date TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # åˆ›å»ºè´¢åŠ¡æŒ‡æ ‡è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS financial_metrics (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            stock_code TEXT,
            year INTEGER,
            metric_name TEXT,
            metric_value REAL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (stock_code) REFERENCES stocks (stock_code)
        )
    ''')
    
    # åˆ›å»ºç´¢å¼•
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_stock_year 
        ON financial_metrics (stock_code, year)
    ''')
    
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_metric_name 
        ON financial_metrics (metric_name)
    ''')
    
    conn.commit()
    conn.close()

def main():
    """ä¸»ç¨‹åº"""
    setup_logger()
    
    logger.info("ğŸš€ å¼€å§‹é‡æ–°å¯¼å…¥ç¼“å­˜æ•°æ®åˆ°æ•°æ®åº“...")
    
    # åˆ›å»ºæ•°æ®åº“
    create_sqlite_database()
    
    # æ¸…ç©ºç°æœ‰æ•°æ®
    clear_database()
    
    cache_dir = 'cache'
    all_results = []
    
    logger.info("ğŸ”„ å¼€å§‹ä»ç¼“å­˜æ–‡ä»¶å¯¼å…¥æ•°æ®...")
    
    # å¤„ç†æ‰€æœ‰æ‰¹æ¬¡ç¼“å­˜æ–‡ä»¶
    batch_files = sorted([f for f in os.listdir(cache_dir) if f.startswith('batch_') and f.endswith('.json')])
    
    if not batch_files:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•ç¼“å­˜æ–‡ä»¶!")
        print("\nğŸ˜” æœªæ‰¾åˆ°ä»»ä½•ç¼“å­˜æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ collect_data.py æ”¶é›†æ•°æ®")
        return
    
    logger.info(f"ğŸ“¦ æ‰¾åˆ° {len(batch_files)} ä¸ªæ‰¹æ¬¡ç¼“å­˜æ–‡ä»¶")
    
    for batch_file in batch_files:
        batch_path = os.path.join(cache_dir, batch_file)
        batch_num = batch_file.replace('batch_', '').replace('.json', '')
        
        logger.info(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_num}: {batch_file}")
        
        try:
            with open(batch_path, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # å¤„ç†ç¼“å­˜æ•°æ®
            batch_results = process_cache_data(cache_data)
            
            if batch_results:
                # è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜åˆ°æ•°æ®åº“
                batch_df = pd.DataFrame(batch_results)
                save_to_sqlite(batch_df)
                
                all_results.extend(batch_results)
                
                logger.info(f"âœ… æ‰¹æ¬¡ {batch_num}: æˆåŠŸå¯¼å…¥ {len(batch_results)} åªè‚¡ç¥¨")
            else:
                logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_num}: æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ‰¹æ¬¡ {batch_num} å¤±è´¥: {e}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    if all_results:
        logger.info(f"ğŸ¯ é‡æ–°å¯¼å…¥å®Œæˆ!")
        logger.info(f"  â€¢ æ€»å…±å¤„ç†äº† {len(batch_files)} ä¸ªæ‰¹æ¬¡")
        logger.info(f"  â€¢ æˆåŠŸå¯¼å…¥ {len(all_results)} åªè‚¡ç¥¨")
        
        # æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
        conn = sqlite3.connect('stock_analysis.db')
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM stocks')
        stock_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM financial_metrics')
        metrics_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(DISTINCT stock_code) FROM financial_metrics')
        stocks_with_data = cursor.fetchone()[0]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æ•°æ®
        cursor.execute('''
            SELECT stock_code, year, metric_name, COUNT(*) as cnt
            FROM financial_metrics 
            GROUP BY stock_code, year, metric_name 
            HAVING COUNT(*) > 1
            LIMIT 5
        ''')
        duplicates = cursor.fetchall()
        
        conn.close()
        
        logger.info(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
        logger.info(f"  â€¢ è‚¡ç¥¨æ€»æ•°: {stock_count}")
        logger.info(f"  â€¢ æœ‰è´¢åŠ¡æ•°æ®çš„è‚¡ç¥¨: {stocks_with_data}")
        logger.info(f"  â€¢ è´¢åŠ¡æŒ‡æ ‡è®°å½•æ•°: {metrics_count}")
        
        if duplicates:
            logger.warning(f"âš ï¸ å‘ç° {len(duplicates)} ç»„é‡å¤æ•°æ®")
            for dup in duplicates:
                logger.warning(f"  é‡å¤: {dup[0]} {dup[1]}å¹´ {dup[2]} (x{dup[3]})")
        else:
            logger.info("âœ… æœªå‘ç°é‡å¤æ•°æ®")
        
        print(f"\nğŸ‰ ç¼“å­˜æ•°æ®é‡æ–°å¯¼å…¥æˆåŠŸ!")
        print(f"ğŸ“ˆ æ•°æ®åº“ä¸­ç°åœ¨æœ‰ {stocks_with_data} åªè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®")
        print(f"ğŸ“Š æ€»å…± {metrics_count} æ¡è´¢åŠ¡æŒ‡æ ‡è®°å½•")
        
        if duplicates:
            print(f"âš ï¸ æ³¨æ„ï¼šå‘ç° {len(duplicates)} ç»„é‡å¤æ•°æ®ï¼Œå»ºè®®æ£€æŸ¥")
        else:
            print("âœ… æ•°æ®æ²¡æœ‰é‡å¤ï¼Œå¯¼å…¥å¹²å‡€!")
        
    else:
        logger.warning("ğŸ˜” æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç¼“å­˜æ•°æ®")

if __name__ == "__main__":
    main() 